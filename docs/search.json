[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, my name is Pranav. The purpose of this blog is to document my projects and thoughts."
  },
  {
    "objectID": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html",
    "href": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html",
    "title": "FastAI Lesson 1: Getting Started",
    "section": "",
    "text": "In this lesson, Jeremy walks through a bird classification example which back in 2015 was considered the bleeding edge of state of the art. 8 years later, it’s hard to believe that I can run this on my own local machine. Even though my training is in computer science, I found some of the definitions and the code in this lesson challenging which is where Chapter 1 was really helpful. I would strongly recommend checking out the definitions in this chapter because they are still used today when talking about more advanced models like GPT-4."
  },
  {
    "objectID": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#summary",
    "href": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#summary",
    "title": "FastAI Lesson 1: Getting Started",
    "section": "",
    "text": "In this lesson, Jeremy walks through a bird classification example which back in 2015 was considered the bleeding edge of state of the art. 8 years later, it’s hard to believe that I can run this on my own local machine. Even though my training is in computer science, I found some of the definitions and the code in this lesson challenging which is where Chapter 1 was really helpful. I would strongly recommend checking out the definitions in this chapter because they are still used today when talking about more advanced models like GPT-4."
  },
  {
    "objectID": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#terminology",
    "href": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#terminology",
    "title": "FastAI Lesson 1: Getting Started",
    "section": "Terminology",
    "text": "Terminology\n\nMachine Learning - The training of programs developed by teaching a computer learn from experience rather than coding the individual steps\nDeep Learning - A computer technique that uses layers of neural networks to extract and transform data. Neural networks layers are trained by algorithms that minimize their errors and improve their accuracy. This is how a network learns to perform a specific task. Deep learning is a sub-discipline of machine learning.\nDataset - A bunch of data ie. images, sounds, text, files or anything else.\nLabel - The data we’re trying to predict ie. dog or cat.\nIndependent Variable - Data that does not include labels\nDependent Variable - the correct label ie. dog or cat. Also called targets.\nArchitecture - The structure of the model we’re trying to fit. A mathematical function that we’re passing the input data and parameters to.\nParameters - The values in the model that change what task it can do and are updated through model training. In Arthur Samuel’s definitions the synonym for parameters is weights which has a different meaning in modern deep learning.\nParameter(Weight) Assignment - Particular choice of values for parameters.\nWeights - A particular type of model parameter.\nFit - Update the model parameters such that the predictions of the model using the input data match the target labels.\nTrain - Synoym for fit.\nPretrained Model - A model that has already been trained, generally using a large dataset and will be fine-tuned ie. resnet class of models.\nFine-Tune - Update a pretrained model for a different task.\nEpoch - One complete pass through the input data.\nLoss - A measure of how good the model is, chosen to drive training via Stochastic Gradient Descent (SGD).\nMetric - A measurement of how good the model is, using the validation set, chosen for human consumption.\nValidation Set - A set of data held out from training, used only for measuring how good the model is.\nTraining Set - The data used for fitting the model; does not include any data from the validation set.\nOverfitting - Training a model in such a way that it remembers specific features of the input data rather than generalizing.\nConvolutional Neural Network (CNN) - A type of neural network that works particularly well for computer vision tasks.\nTransfer Learning - Using a pretrained model for a task different to what it was originally trained for.\nHead Layer - When using a pretrained model, replace the last layer with one or more layers with randomized weights of an appropriate size for the dataset you are working with. This customizes a model specifically for your task when using a pretrained model."
  },
  {
    "objectID": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#limitations-of-machine-learning",
    "href": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#limitations-of-machine-learning",
    "title": "FastAI Lesson 1: Getting Started",
    "section": "Limitations of Machine Learning",
    "text": "Limitations of Machine Learning\n\nA model cannot be created without data\nA model can only learn to operate on patterns seen in input data used to train it\nThis learning approach only creates predictions not recommend actions\nWe need labels + data (pictures of dogs and cats that have labels saying which ones are dogs and which ones are cats)"
  },
  {
    "objectID": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#is-it-a-bird-example",
    "href": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#is-it-a-bird-example",
    "title": "FastAI Lesson 1: Getting Started",
    "section": "Is It a Bird? Example",
    "text": "Is It a Bird? Example\nThe following code in this example is created and written by Jeremy Howard and FastAI as found in the example Is it a bird? Creating a model from your own data. My modification was adding comments for myself to the data block section so that I could understand what each part of the datablock is doing.\n\nimport os \niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif iskaggle:\n    !pip install -Uqq fastai duckduckgo_search\n\n\nStep 1: Gather Data\n\nfrom duckduckgo_search import ddg_images \nfrom fastcore.all import * \n\n# helper function for searching for images \ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n\nurls = search_images('bird photos', max_images=1)\nurls[0]\n\nSearching for 'bird photos'\n\n\n/opt/conda/lib/python3.10/site-packages/duckduckgo_search/compat.py:40: UserWarning: ddg_images is deprecated. Use DDGS().images() generator\n  warnings.warn(\"ddg_images is deprecated. Use DDGS().images() generator\")\n\n\n'https://images.alphacoders.com/492/492674.jpg'\n\n\n\nfrom fastdownload import download_url \nfrom fastai.vision.all import *\ndest = 'bird.jpg'\ndownload_url(urls[0], dest, show_progress=False)\nim = Image.open(dest)\nim.to_thumb(256, 256)\n\n\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}\"\n\n\n\n\n\n\ndownload_url(search_images('forest photos', max_images=1)[0], 'forest.jpg', \n             show_progress=False)\nImage.open('forest.jpg').to_thumb(256, 256)\n\nSearching for 'forest photos'\n\n\n/opt/conda/lib/python3.10/site-packages/duckduckgo_search/compat.py:40: UserWarning: ddg_images is deprecated. Use DDGS().images() generator\n  warnings.warn(\"ddg_images is deprecated. Use DDGS().images() generator\")\n\n\n\n\n\n\nsearches = 'forest', 'bird'\npath = Path('bird_or_not')\nfrom time import sleep \n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10) # sleep between searches to avoid spamming server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10) # sleep between searches to avoid spamming server \n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10) # sleep between searches to avoid spamming server \n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'forest photo'\nSearching for 'forest sun photo'\nSearching for 'forest shade photo'\nSearching for 'bird photo'\nSearching for 'bird sun photo'\nSearching for 'bird shade photo'\n\n\n/opt/conda/lib/python3.10/site-packages/duckduckgo_search/compat.py:40: UserWarning: ddg_images is deprecated. Use DDGS().images() generator\n  warnings.warn(\"ddg_images is deprecated. Use DDGS().images() generator\")\n\n\n\n\nStep 2: Train Model\n\n# remove images that failed to download properly \nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n3\n\n\n\n# split data into training set, validation set \ndls = DataBlock(\n    # specify input type(image), output type(category aka label)\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    # split data into 80% training data, and 20% validation data\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    # define the label \n    get_y=parent_label,\n    # standardize and resize all images to 192 x 192\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n# train resnet on the data\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.744936\n0.402673\n0.156250\n00:01\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.178611\n0.097689\n0.031250\n00:01\n\n\n1\n0.117756\n0.136063\n0.031250\n00:01\n\n\n2\n0.079709\n0.154602\n0.031250\n00:01\n\n\n\n\n\n\n\nStep 3: Test Model\n\nis_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\nprint(f\"This is a : {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a : bird.\nProbability it's a bird: 0.9996"
  },
  {
    "objectID": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#picasso-cubist-painting-or-georges-braque-cubist-painting",
    "href": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#picasso-cubist-painting-or-georges-braque-cubist-painting",
    "title": "FastAI Lesson 1: Getting Started",
    "section": "Picasso Cubist Painting or Georges Braque Cubist Painting",
    "text": "Picasso Cubist Painting or Georges Braque Cubist Painting\nThis code was written by me based on Jeremy and FastAI’s bird example. I picked this example because of an interest in art, the similarity between Picasso and Braque’s cubist art, and the question of whether a computer would be able to tell the difference between the two artists when shown a random cubist painting by either Picasso or Braque.\n\nStep 1: Gather Data\n\nurls = search_images('Pablo Picasso Cubist Painting', max_images=1)\nurls[0]\n\nSearching for 'Pablo Picasso Cubist Painting'\n\n\n/opt/conda/lib/python3.10/site-packages/duckduckgo_search/compat.py:40: UserWarning: ddg_images is deprecated. Use DDGS().images() generator\n  warnings.warn(\"ddg_images is deprecated. Use DDGS().images() generator\")\n\n\n'http://www.baaqii.com/promanage/productimage/OP/OP0288.jpg'\n\n\n\nfrom fastdownload import download_url \nfrom fastai.vision.all import *\ndest = 'picasso.jpg'\ndownload_url(urls[0], dest, show_progress=False)\nim = Image.open(dest)\nim.to_thumb(256, 256)\n\n\n\n\n\ndownload_url(search_images('Georges Braque Cubist Painting', max_images=1)[0], \n             'braque.jpg', \n             show_progress=False)\nImage.open('braque.jpg').to_thumb(256, 256)\n\nSearching for 'George Braque Cubist Painting'\n\n\n\n\n\n\nsearches = 'Pablo Picasso', 'Georges Braque'\npath = Path('picasso_or_braque')\nfrom time import sleep \n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} cubist painting'))\n    sleep(10) # sleep between searches to avoid spamming server\n    download_images(dest, urls=search_images(f'{o} fauvist painting'))\n    sleep(10) # sleep between searches to avoid spamming server \n    download_images(dest, urls=search_images(f'{o} geometric painting'))\n    sleep(10) # sleep between searches to avoid spamming server \n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'Pablo Picasso cubist painting'\nSearching for 'Pablo Picasso fauvist painting'\nSearching for 'Pablo Picasso geometric painting'\nSearching for 'George Braque cubist painting'\nSearching for 'George Braque fauvist painting'\nSearching for 'George Braque geometric painting'\n\n\n\n\nStep 2: Train Model\n\n# remove images that failed to download properly \nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n2\n\n\n\n# split data into training set, validation set \ndls = DataBlock(\n    # specify input type(image), output type(category aka label)\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    # split data into 80% training data, and 20% validation data\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    # define the label \n    get_y=parent_label,\n    # standardize and resize all images to 192 x 192\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n# train resnet on the data\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.963409\n0.409861\n0.157143\n00:01\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.281930\n0.232642\n0.057143\n00:01\n\n\n1\n0.227495\n0.084337\n0.028571\n00:01\n\n\n2\n0.163790\n0.051675\n0.014286\n00:01\n\n\n\n\n\n\n\nStep 3: Test Model\nThere is something wrong here because the probability is incorrect. I can’t figure out whether I messed up in the data phase, architecture choice (resnet34 instead of resnet18), or a programming mistake. My guess is that the program should have a probability of choosing the right result around the same percentage as the bird example. If anyone knows what the issue might be, please reach out.\n\nis_picasso,_,probs = learn.predict(PILImage.create('picasso.jpg'))\nprint(f\"This is a: {is_picasso}.\")\nprint(f\"Probability it's a picasso: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: Pablo Picasso.\nProbability it's a picasso: 0.0006"
  },
  {
    "objectID": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#resources",
    "href": "posts/fastai-lesson1/picasso-or-braque-cubist-painting.html#resources",
    "title": "FastAI Lesson 1: Getting Started",
    "section": "Resources",
    "text": "Resources\n\nFastAI Lesson 1: Getting Started\nFastAI Chapter 1, Intro\nIs it a bird? Creating a model from your own data\nJupyter Notebook 101\nFastAI Docs"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is my first blog post. Welcome!\nI decided to start a blog inspired by Jeremy Howard’s Lecture 0 from the FastAI Course. Jeremy and FastAI used to maintain a blogging and publication tool called FastPages but transitioned to a new publication system called Quarto.\nThis blog is written in Quarto. Why Quarto? In the past I had attempted to used Medium and Substack but never fully spent the time to learn the tools to write a blog post. I decided to learn and publish with Quarto because of its capabilities to produce high quality scientific and technical documents with the ability to embed code and visualizations for review. Another reason why I like Quarto is how easy it is to write markdown and publish a blog.\nGoing forward I hope to use Quarto to write about my programming projects, thoughts,and improve my writing."
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "",
    "text": "Finally back after a long hiatus. I took a break from posting and FASTAI to try Advent of Code and get back to interview prep but I’m back. Normally I only write a single summary for a blog post but this time I’m writing two summaries because Chapter 4 of the book goes deeper into the foundations of neural networks than the lecture video."
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#announcements",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#announcements",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "",
    "text": "Finally back after a long hiatus. I took a break from posting and FASTAI to try Advent of Code and get back to interview prep but I’m back. Normally I only write a single summary for a blog post but this time I’m writing two summaries because Chapter 4 of the book goes deeper into the foundations of neural networks than the lecture video."
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#acknowledgements",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#acknowledgements",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nAll of this code was written by Jeremy Howard and the authors of the FastAI book. My modification to their code was adding print statements and comments to understand what each line of code was doing."
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#summary---fastai-lesson-3-video",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#summary---fastai-lesson-3-video",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Summary - FastAI Lesson 3 Video",
    "text": "Summary - FastAI Lesson 3 Video\nIn this lesson, Jeremy gives a high level overview of pytorch, gradient descent and the evolution of models. Most of the video focuses on approximating a quadratic equation and building the intuition towards how a neural network works. Towards the end of the video, Jeremy introduces the Titanic dataset and how to do some basic modeling with excel."
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#summary-fastai-chapter-4",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#summary-fastai-chapter-4",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Summary FastAI Chapter 4",
    "text": "Summary FastAI Chapter 4\nIn Chapter 4, the FastAI book authors use the MNIST dataset as a case study to understand how pytorch and the fastai library work under the hood. I found this chapter to be a mind bender because I struggled to wrap my head around the concept of a tensor and the kinds of operations you can do on a tensor. Another concept I struggled with was the meaning of rank and dimension of tensors which are not the same as the meaning of rank and dimension in linear algebra and physics (will go more into this later). By the end of this chapter, I understood the following concepts:\n\nwhat a tensor represents and performing operations on a tensor\nhow to set up a classifier using pytorch\nhow a training loop, optimizer, batch work in pytorch and fastai\nthe operations and functions that fastai provides a wrapper on top of\n\nI do agree with Jeremy that this book chapter might scare people away because the jargon combined with the mathematical concepts but its definitely worth spending a few days getting through since you develop a deeper understanding of pytorch and the deep learning process."
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#jeremy-howards-advice",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#jeremy-howards-advice",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Jeremy Howard’s Advice",
    "text": "Jeremy Howard’s Advice\nJeremy provides some really good insights and advice in the lecture video not captured in the book or kaggle notebooks. This is my summary of the advice:\n\nModel: Mathematical function consisting of a Matrix Multiply operation + nonlinearity (RELU, Sigmoid etc)\nThings to thing about when picking a class of model for a problem we’re trying to solve:\n\nHow fast is the model\nHow much memory does it consume\nHow accurate is it\n\nModels fit functions to data and try to recognize patterns in data that we give it\n\n\n# load libraries and imports\n!pip install -Uqq fastai duckduckgo_search\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\nfrom PIL import Image\nfrom functools import partial\n\n# import fastai libraries\nfrom fastai.vision.all import *\n\n# update grayscale colormap for matplotlib\nmatplotlib.rc('image', cmap='Greys')"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#mnist-dataset",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#mnist-dataset",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "MNIST Dataset",
    "text": "MNIST Dataset\nTo show how neural networks work, the FastAI authors use the MNIST dataset as a case study. MNIST is a dataset containing handwritten digits collected by NIST (National Institute of Standards and Technology) and turned into dataset by Yann Lecun and his colleagues. For more information about Lecun and MNIST I would recommend reading the book chapter.\nThe MNIST dataset follows traditional machine learning dataset layouts: Training Data and Validation Data each containing images associated with a particular digit between 0-9.\n\n# LOAD MNIST DATA\npath = untar_data(URLs.MNIST_SAMPLE)\nPath.BASE_PATH = path\nprint(f\"Contents of MNIST DATA: {path.ls()}\")\n\n# MNIST Training Data\nprint(f\"MNIST Training Data Directory Contents: {(path/'train').ls()}\")\n\n# MNIST Training Data for 3s and 7s in sorted order\nthrees = (path/'train'/'3').ls().sorted()\nsevens = (path/'train'/'7').ls().sorted()\n# print(f\"Sorted Training Data for 3: {threes}\")\n\n# Training Data Example\nim3_path = threes[1]\nim3 = Image.open(im3_path)\nprint(f\"Test Image of 3 from 3 training data set\")\nim3\n\nContents of MNIST DATA: [Path('train'), Path('valid'), Path('labels.csv')]\nMNIST Training Data Directory Contents: [Path('train/7'), Path('train/3')]\nTest Image of 3 from 3 training data set"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#representing-images-as-numbers",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#representing-images-as-numbers",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Representing Images as Numbers",
    "text": "Representing Images as Numbers\nImages are represented on computers as an array of pixels where each index contains a list of 3 numbers between 0-255 corresponding to a particular color according to RGB. Assembling all of these colors together we get an image.\nThe MNIST images are represented differently: each index in the image array contains a number between 0-255 where 0 represents white and 255 black. All other values between 0-255 represent a different shade of gray. A unique digit image in the MNIST data is then defined by the black and gray pixels that together outline and define the digit. The size of an image in the MNIST data is 28 x 28 which is 784 pixels in the Image Array.\nIn the following examples, [4:10, 4:10] means the following: request rows from index 4 (included) to 10(not included) and the same for the columns. Numpy and Pytorch index from top to bottom and left to right.\nIn the image slice below, we select a part of the digit with just the top part and then color code the slice based on the values in the slice with their mapping in the gray scale (0-255) where 0 represents white and 255 black.\n\n# MNIST image dimensions are 28 x 28 = 784 pixel array\nprint(f\"im3 represented as an array of numbers using numpy array\")\narray(im3)\n\nim3 represented as an array of numbers using numpy array\n\n\narray([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254,\n        255, 254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234,\n        196, 253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,\n          4,  10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,\n          0,   0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,\n          0,  43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0, 249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101,\n        223, 253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253,\n        253, 253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253,\n        253, 253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,\n         98, 208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,  98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42,\n        150, 252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240,\n        253, 253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253,\n        253, 197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,\n         67,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]], dtype=uint8)\n\n\n\n# Slice of im3\n# [4:10, 4:10] - get rows and columns starting from 4(included) to 10 (excluded)\n# Numpy Array representation\narray(im3)[4:10,4:10]\n\narray([[  0,   0,   0,   0,   0,   0],\n       [  0,   0,   0,   0,   0,  29],\n       [  0,   0,   0,  48, 166, 224],\n       [  0,  93, 244, 249, 253, 187],\n       [  0, 107, 253, 253, 230,  48],\n       [  0,   3,  20,  20,  15,   0]], dtype=uint8)\n\n\n\n# MNIST image dimensions are 28 x 28 = 784 pixel array\nprint(f\"im3 represented as an array of numbers using tensors\")\ntensor(im3)\n\nim3 represented as an array of numbers using tensors\n\n\ntensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254, 255,\n         254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234, 196,\n         253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,   4,\n          10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,   0,\n           0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,   0,\n          43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101, 223,\n         253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253, 253,\n         253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253, 253,\n         253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,  98,\n         208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 150,\n         252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240, 253,\n         253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253, 253,\n         197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,  67,\n           1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n       dtype=torch.uint8)\n\n\n\n# Slice of im3\n# [4:10, 4:10] - get rows and columns starting from 4(included) to 10 (excluded)\n# Tensor representation\ntensor(im3)[4:10, 4:10]\n\ntensor([[  0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,  29],\n        [  0,   0,   0,  48, 166, 224],\n        [  0,  93, 244, 249, 253, 187],\n        [  0, 107, 253, 253, 230,  48],\n        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)\n\n\n\n# slice data to obtain the top part of the number and color code data to show digit outline\n# slice data rows: 4(included)-15(excluded)\n# slice data columns: 4(included)-22(excluded)\nim3_t = tensor(im3)\ndf = pd.DataFrame(im3_t[4:15,4:22])\ndf.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')\n\n\n\n\n\n\n \n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n29\n150\n195\n254\n255\n254\n176\n193\n150\n96\n0\n0\n0\n\n\n2\n0\n0\n0\n48\n166\n224\n253\n253\n234\n196\n253\n253\n253\n253\n233\n0\n0\n0\n\n\n3\n0\n93\n244\n249\n253\n187\n46\n10\n8\n4\n10\n194\n253\n253\n233\n0\n0\n0\n\n\n4\n0\n107\n253\n253\n230\n48\n0\n0\n0\n0\n0\n192\n253\n253\n156\n0\n0\n0\n\n\n5\n0\n3\n20\n20\n15\n0\n0\n0\n0\n0\n43\n224\n253\n245\n74\n0\n0\n0\n\n\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n249\n253\n245\n126\n0\n0\n0\n0\n\n\n7\n0\n0\n0\n0\n0\n0\n0\n14\n101\n223\n253\n248\n124\n0\n0\n0\n0\n0\n\n\n8\n0\n0\n0\n0\n0\n11\n166\n239\n253\n253\n253\n187\n30\n0\n0\n0\n0\n0\n\n\n9\n0\n0\n0\n0\n0\n16\n248\n250\n253\n253\n253\n253\n232\n213\n111\n2\n0\n0\n\n\n10\n0\n0\n0\n0\n0\n0\n0\n43\n98\n98\n208\n253\n253\n253\n253\n187\n22\n0"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#baseline-model-pixel-similarity",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#baseline-model-pixel-similarity",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Baseline Model: Pixel Similarity",
    "text": "Baseline Model: Pixel Similarity\nThe problem we’re trying to solve is the following: How do we write a computer program to be able to distinguish between images of handwritten 3 and 7 digits.\nThe first approach we try is Pixel Similarity. The FASTAI book authors define this as the following:\n\nTake the average pixel value for every pixel of the 3 images and do the same for the 7 images. These averages will produce a baseline image 3 and image 7.\nGo through every image in the 3 and 7 images and compare them to the baseline images to see which digit they are most similar to\n\n\n# Create a list of tensors for each image in 3 and 7 directories\nthree_tensors = [tensor(Image.open(o)) for o in threes]\nseven_tensors = [tensor(Image.open(o)) for o in sevens]\n\nprint(f\"Number of images in threes: {len(threes)}\")\nprint(f\"Number of images in three tensors: {len(three_tensors)}\")\nprint(f\"Number of images in sevens: {len(sevens)}\")\nprint(f\"Number of images in seven tensors: {len(seven_tensors)}\")\n\n# verify images\nshow_image(three_tensors[1])\nshow_image(seven_tensors[1])\n\nNumber of images in threes: 6131\nNumber of images in three tensors: 6131\nNumber of images in sevens: 6265\nNumber of images in seven tensors: 6265\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\n\nThe way I understand tensors is that they are data structures for storing information. The way I understand the stack operation is storing all the images into a pile of images that we then then can average all the pixel values for each pixel index in the image.\n\n# Compute the average intensity of each pixel across all images for 3 and 7\nstacked_sevens = torch.stack(seven_tensors).float() / 255\nstacked_threes = torch.stack(three_tensors).float() / 255\n\nprint(f\"stacked_sevens shape: {stacked_sevens.shape}\")\nprint(f\"stacked_sevens tensor rank: {len(stacked_sevens.shape)}\")\nprint(f\"stacked_threes shape: {stacked_threes.shape}\")\nprint(f\"stacked_threes tensor rank: {len(stacked_threes.shape)}\")\n\nstacked_sevens shape: torch.Size([6265, 28, 28])\nstacked_sevens tensor rank: 3\nstacked_threes shape: torch.Size([6131, 28, 28])\nstacked_threes tensor rank: 3\n\n\nIn this step, we take the list of tensor images and condense them down into a new image where each pixel index in this new image is the average of all the values at a particular index.\n\n # Average of all image tensors by taking mean along the 0 dimension (collapse all the rows into a single row) of stacked 3 rank tensors\nmean3 = stacked_threes.mean(0)\nmean7 = stacked_sevens.mean(0)\nprint(f\"mean3 shape: {mean3.shape}\")\nprint(f\"mean3 tensor rank: {len(mean3.shape)}\")\nprint(f\"mean7 shape: {mean7.shape}\")\nprint(f\"mean7 tensor rank: {len(mean7.shape)}\")\nshow_image(mean3)\nshow_image(mean7)\n\nmean3 shape: torch.Size([28, 28])\nmean3 tensor rank: 2\nmean7 shape: torch.Size([28, 28])\nmean7 tensor rank: 2\n\n\n&lt;Axes: &gt;"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#measuring-distance",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#measuring-distance",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Measuring Distance",
    "text": "Measuring Distance\nTo compare the baseline image with a randomly chosen image from one of the datasets we need to measure the difference between pixels such that we have a standardized form so that the differences accurately reflect what pixels are dark and light when comparing the two images.\n\n# Mean Absolute Difference (L1 Norm)\na_3 = stacked_threes[1]\na_7 = stacked_sevens[1]\n\ndist_3_abs = (a_3 - mean3).abs().mean()\ndist_7_abs = (a_7 - mean7).abs().mean()\n\nprint(f\"Mean Absolute Difference between 3 image and ideal 3 image: {dist_3_abs}\")\nprint(f\"Mean Absolute Difference between 7 image and ideal 7 image: {dist_7_abs}\")\n\n# see how close 3 is to ideal 7\ndist_test_abs = (a_3 - mean7).abs().mean()\nprint(f\"Mean Absolute Difference between 3 image and ideal 7 image: {dist_test_abs}\")\n\nMean Absolute Difference between 3 image and ideal 3 image: 0.11143654584884644\nMean Absolute Difference between 7 image and ideal 7 image: 0.13037648797035217\nMean Absolute Difference between 3 image and ideal 7 image: 0.15861910581588745\n\n\n\n# Root Mean Squared Error (L2 Norm)\na_3 = stacked_threes[1]\na_7 = stacked_sevens[1]\n\ndist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\ndist_7_sqr = ((a_7 - mean7)**2).mean().sqrt()\ndist_test_sqr = ((a_3 - mean7)**2).mean().sqrt()\nprint(f\"Root Mean Squared Difference between 3 image and ideal 3 image: {dist_3_sqr}\")\nprint(f\"Root Mean Squared Difference between 7 image and ideal 7 image: {dist_7_sqr}\")\n\n# see how close 3 is to ideal 7\nprint(f\"Root Mean Squared Difference between 3 image and ideal 7 image: {dist_test_sqr}\")\n\nRoot Mean Squared Difference between 3 image and ideal 3 image: 0.20208320021629333\nRoot Mean Squared Difference between 7 image and ideal 7 image: 0.2584923207759857\nRoot Mean Squared Difference between 3 image and ideal 7 image: 0.30210891366004944\n\n\n\n# Pytorch Mean Squared Error and Mean Absolute Value Loss\nprint(f\"Pytorch Mean Absolute Value Loss between 3 image and ideal 7 image: {F.l1_loss(a_3.float(), mean7)}\")\nprint(f\"Pytorch Mean Squared Error Loss between 3 image and ideal 7 image: {F.mse_loss(a_3, mean7).sqrt()}\")\n\nPytorch Mean Absolute Value Loss between 3 image and ideal 7 image: 0.15861910581588745\nPytorch Mean Squared Error Loss between 3 image and ideal 7 image: 0.30210891366004944"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#pytorch-numpy",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#pytorch-numpy",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Pytorch + Numpy",
    "text": "Pytorch + Numpy\nThe main difference between pytorch and numpy is that pytorch supports using the GPU and calculating gradients which numpy does not.\n\ndata = [[1, 2, 3], [4, 5, 6]]\n# numpy array\narr = array(data)\n# tensor\ntns = tensor(data)\n\n# select a row\nprint(f\"select the second row of tensor: {tns[1]}\")\n\n# select a column\nprint(f\"select the second column of tensor: {tns[:1]}\")\n\n# slicing\nprint(f\"select slice of tensor: {tns[1, 1:3]}\")\n\n# addition\nprint(f\"Addition with tensors: {tns + 1}\")\n\n# types\nprint(f\"tensor type: {tns.type()}\")\n\n# scale and update tensor type\nprint(f\"changing tensor type from int to float: {tns * 1.5}\")\n\nselect the second row of tensor: tensor([4, 5, 6])\nselect the second column of tensor: tensor([[1, 2, 3]])\nselect slice of tensor: tensor([5, 6])\nAddition with tensors: tensor([[2, 3, 4],\n        [5, 6, 7]])\ntensor type: torch.LongTensor\nchanging tensor type from int to float: tensor([[1.5000, 3.0000, 4.5000],\n        [6.0000, 7.5000, 9.0000]])"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#computing-metrics",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#computing-metrics",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Computing Metrics",
    "text": "Computing Metrics\nA metric is a number that is calculated based on the predictions of the model and the correct labels and inform us how good the model is. For classification models, accuracy is a popular metric.\n\n# create validation data set\nvalid_3_tens = torch.stack([tensor(Image.open(o))\n                            for o in (path/'valid'/'3').ls()])\nvalid_3_tens = valid_3_tens.float() / 255\nvalid_7_tens = torch.stack([tensor(Image.open(o))\n                            for o in (path/'valid'/'7').ls()])\nvalid_7_tens = valid_7_tens.float() / 255\n\nprint(f\"3 validation set shape: {valid_3_tens.shape}\")\nprint(f\"3 validation set tensor rank: {len(valid_3_tens.shape)}\")\nprint(f\"7 validation set shape: {valid_7_tens.shape}\")\nprint(f\"7 validation set tensor rank: {len(valid_7_tens.shape)}\")\n\n3 validation set shape: torch.Size([1010, 28, 28])\n3 validation set tensor rank: 3\n7 validation set shape: torch.Size([1028, 28, 28])\n7 validation set tensor rank: 3\n\n\n\n# MNIST Data Distance Function\ndef mnist_distance(a, b):\n  # (-1, -2) represent a range of axes. Tell Pytorch to take the mean ranging over the values\n  # indexed by the last two axes of the tensor (horizontal and vertical dimensions of the image)\n  # leaves only the first tensor axis which indexes over images and the final size -&gt; averaged the intensity of all the pixels\n  # in the image\n  return (a - b).abs().mean((-1,-2))\nprint(f\"Distance function measuring the distance between 3 image and ideal 3 image: {mnist_distance(a_3, mean3)}\")\n\n# measure distance between validation set 3 and ideal 3 tensor\nvalid_3_dist = mnist_distance(valid_3_tens, mean3)\nprint(f\"Distance between validation set 3 image and ideal training data set 3 image: {valid_3_dist}\")\nprint(f\"Valid 3 distance tensor shape: {valid_3_dist.shape}\")\nprint(f\"Valid 3 distance tensor rank: {len(valid_3_dist.shape)}\")\n\nDistance function measuring the distance between 3 image and ideal 3 image: 0.11143654584884644\nDistance between validation set 3 image and ideal training data set 3 image: tensor([0.1163, 0.1464, 0.1188,  ..., 0.1508, 0.1018, 0.1285])\nValid 3 distance tensor shape: torch.Size([1010])\nValid 3 distance tensor rank: 1\n\n\n\n# check if image is a 3\ndef is_3(x):\n  return mnist_distance(x, mean3) &lt; mnist_distance(x, mean7)\n\nprint(f\"Check if 3 image is actually a 3 image as a boolean: {is_3(a_3)}\")\n# 1.0 - true\n# 0.0 - false\nprint(f\"Check if 3 image is actually a 3 image as a float: {is_3(a_3).float()}\")\n\n# check all 3 images\nprint(f\"check if all 3 images in validation set are 3 images: {is_3(valid_3_tens)}\")\n\nCheck if 3 image is actually a 3 image as a boolean: True\nCheck if 3 image is actually a 3 image as a float: 1.0\ncheck if all 3 images in validation set are 3 images: tensor([True, True, True,  ..., True, True, True])\n\n\n\n# Compute Accuracy of 3 and 7 Images\naccuracy_3s = is_3(valid_3_tens).float() .mean()\naccuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n\nprint(f\"Model accuracy for classifying 3 images: {accuracy_3s}\")\nprint(f\"Model accuracy for classifying 7 images: {accuracy_7s}\")\nprint(f\"Average model accuracy for classifying 3 and 7 images: {(accuracy_3s+accuracy_7s)/2}\")\n\nModel accuracy for classifying 3 images: 0.9168316721916199\nModel accuracy for classifying 7 images: 0.9854085445404053\nAverage model accuracy for classifying 3 and 7 images: 0.951120138168335"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#stochastic-gradient-descent",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#stochastic-gradient-descent",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Stochastic Gradient Descent",
    "text": "Stochastic Gradient Descent\nIn the Pixel Similarity approach from above, we don’t have a way for the model to learn and improve its accuracy. Instead of trying to compare an image with an ideal image, we can use Stochastic Gradient Descent (SGD) to look at each individual pixel and come up with a set of weights with large weights associated with pixels that are the most black for a particular label (ie. digit in MNIST data) using Arthur Samuel’s definition of machine learning\n\nStochastic Gradient Descent Steps for an Image Classifier\n\ninitialize weights\nCalculate Predictions\nBased on the predictions, calculate how good the model is (its loss)\nCalculate the gradient which measures for each weight, how changing that weight would change the loss\nStep (change) all the weights based on Step 4\nGo back to Step 2 and repeat the process\nIterate until you decide to stop the training process until you decide the model is good enough for your problem\n\nThe problem below is an example from the FastAI Book simulating a roller coaster and trying to find a function that best fits the data to understand how speed changes over time\n\n# Roller Coaster Problem with Stochastic Gradient Descent\n# generate data\ntime = torch.arange(0,20).float()\nspeed = torch.randn(20) * 3 + 0.75 * (time - 9.5)**2 + 1\nplt.scatter(time,speed)\n\n# use SGD to find a function that fits the data for the rollercoaster data\n# t - the time when we are measuring the rollercoaster speed\n# params - the values that define which quadratic we're trying\ndef f(t, params):\n    a,b,c = params\n    return a * (t**2) + (b * t) + c\n\n# Define a loss function - returns a value based on a prediction and a target\n# where lower values of the functions correspond to better predictions. Need\n#  loss function to return lower values when predictions are more accurate, as\n#  SGD is trying to minimize this loss. For continuous data, Mean Square Error is\n#  frequently used\ndef mse(preds, targets):\n  return ((preds-targets)**2).mean()\n\n# SGD Process\n# function for visualizing how close our predictions are to targets\ndef show_preds(preds, ax=None):\n    if ax is None: ax=plt.subplots()[1]\n    ax.scatter(time, speed)\n    ax.scatter(time, to_np(preds), color='red')\n    ax.set_ylim(-300,100)\n\n# 1. initialize weights\nparams = torch.randn(3).requires_grad_()\nprint(f\"The parameter values after initialization: {params}\")\norig_params = params.clone()\nprint(f\"The original parameters: {orig_params}\")\n\n# 2. Calculate Predictions\npreds = f(time, params)\nshow_preds(preds)\n\n# 3. Based on the predictions, calculate how good the model is (its loss)\nloss = mse(preds, speed)\nprint(f\"Loss value: {loss}\")\n\n# 4. Calculate the gradient which measures for each weight, how changing that weight would change the loss\nloss.backward()\nprint(f\"Gradient values for each argument: {params.grad}\")\n# Calculate approximation of how parameters need to change\nprint(f\"Test a new gradient with a learning rate of 1e^-5: {params.grad * 1e-5}\")\nprint(f\"Parameter values after computing the gradient: {params}\")\n\n# 5. Step (change) all the weights based on Step 4\nlearning_rate = 1e-5\nparams.data -= learning_rate * params.grad.data\nparams.grad = None\n# Check if loss has improved\npreds = f(time, params)\nmse(preds, speed)\nshow_preds(preds)\n\n# 6. Go back to Step 2 and repeat the process\ndef apply_step(params, prn=True):\n    preds = f(time, params)\n    loss = mse(preds, speed)\n    loss.backward()\n    params.data -= learning_rate * params.grad.data\n    params.grad = None\n    if prn:\n      print(f\"Loss Value: {loss.item()}\")\n    return preds\n\nfor i in range(10):\n  apply_step(params)\nparams = orig_params.detach().requires_grad_()\n\n# 7. Iterate until you decide to stop the training process until you decide the model is good enough for your problem\n_,axs = plt.subplots(1,4,figsize=(12,3))\nfor ax in axs: show_preds(apply_step(params, False), ax)\nplt.tight_layout()\n\nThe parameter values after initialization: tensor([ 0.2816,  0.9605, -1.2062], requires_grad=True)\nThe original parameters: tensor([ 0.2816,  0.9605, -1.2062], grad_fn=&lt;CloneBackward0&gt;)\nLoss value: 1770.0677490234375\nGradient values for each argument: tensor([11310.8789,   742.4634,    34.8602])\nTest a new gradient with a learning rate of 1e^-5: tensor([0.1131, 0.0074, 0.0003])\nParameter values after computing the gradient: tensor([ 0.2816,  0.9605, -1.2062], requires_grad=True)\nLoss Value: 848.1575927734375\nLoss Value: 673.7000732421875\nLoss Value: 640.683349609375\nLoss Value: 634.4315795898438\nLoss Value: 633.2445068359375\nLoss Value: 633.0159301757812\nLoss Value: 632.9686279296875\nLoss Value: 632.9556884765625\nLoss Value: 632.94921875\nLoss Value: 632.9440307617188"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#building-the-mnist-image-classifier",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#building-the-mnist-image-classifier",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Building the MNIST Image Classifier",
    "text": "Building the MNIST Image Classifier\n\nTraining Dataset\n\n# Build Training Dataset\n# -1 view function -&gt; make this axis as big as necessary to fit all the data\ntrain_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\ntrain_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n\nprint(f\"train_x data shape: {train_x.shape}\")\nprint(f\"train_x data tensor rank: {len(train_x.shape)}\")\nprint(f\"train_y data shape: {train_y.shape}\")\nprint(f\"train_y data tensor rank: {len(train_y.shape)}\")\n\ntrain_x data shape: torch.Size([12396, 784])\ntrain_x data tensor rank: 2\ntrain_y data shape: torch.Size([12396, 1])\ntrain_y data tensor rank: 2\n\n\n\n\nValidation Dataset\n\n# Build Validation Dataset\nvalid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\nvalid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\nprint(f\"valid_x data shape: {valid_x.shape}\")\nprint(f\"valid_x data tensor rank: {len(valid_x.shape)}\")\nprint(f\"valid_y data shape: {valid_y.shape}\")\nprint(f\"valid_y data tensor rank: {len(valid_y.shape)}\")\n\nvalid_x data shape: torch.Size([2038, 784])\nvalid_x data tensor rank: 2\nvalid_y data shape: torch.Size([2038, 1])\nvalid_y data tensor rank: 2\n\n\n\n# Build a Dataset object(training data) for PyTorch\n# Dataset is required to return a tuple of (x, y) when indexed\ndset = list(zip(train_x,train_y))\nx,y = dset[0]\nprint(f\"datset x shape: {x.shape}\")\nprint(f\"dataset x tensor rank: {len(x.shape)}\")\nprint(f\"datset y shape: {y.shape}\")\nprint(f\"dataset y tensor rank: {len(y.shape)}\")\n\ndatset x shape: torch.Size([784])\ndataset x tensor rank: 1\ndatset y shape: torch.Size([1])\ndataset y tensor rank: 1\n\n\n\n# Build a Dataset object(validation data) for PyTorch\n# Dataset is required to return a tuple of (x, y) when indexed\nvalid_dset = list(zip(valid_x,valid_y))\n\n\n\nInitialize Model Weights\n\n# Initialize model weights\ndef init_params(size, std=1.0):\n  return (torch.randn(size)*std).requires_grad_()\n\nweights = init_params((28 * 28,1))\n\n# Initialize a Bias Value\n# need a bias to ensure its not 0 when the pixels are 0\nbias = init_params(1)\n\n\n# Calculate a prediction for one image\nprint(f\"Prediction for a single image from training data: {(train_x[0]*weights.T).sum() + bias}\")\n\nPrediction for a single image from training data: tensor([-4.6132], grad_fn=&lt;AddBackward0&gt;)\n\n\n\n\nLinear Classifier\n\n# Matrix Multiplication\n#  Create a linear combination for the prediction values\n# compute predictions for all the images in the training data\ndef linear1(xb):\n  return xb@weights + bias\npreds = linear1(train_x)\nprint(f\"Predictions\")\nprint(preds)\nprint(f\"Prediction shape: {preds.shape}\")\nprint(f\"Prediction tensor rank: {len(preds.shape)}\")\n\nPredictions\ntensor([[-4.6132],\n        [-8.5214],\n        [-6.7243],\n        ...,\n        [-6.6400],\n        [ 3.2664],\n        [-6.1007]], grad_fn=&lt;AddBackward0&gt;)\nPrediction shape: torch.Size([12396, 1])\nPrediction tensor rank: 2\n\n\n\n# Check accuracy of prediction\ncorrects = (preds&gt;0.0).float() == train_y\nprint(f\"Accuracy of Predictions: {corrects}\")\nprint(f\"Average accuracy of all predictions: {corrects.float().mean().item()}\")\n\nAccuracy of Predictions: tensor([[False],\n        [False],\n        [False],\n        ...,\n        [ True],\n        [False],\n        [ True]])\nAverage accuracy of all predictions: 0.36156824231147766\n\n\n\n# Improve Accuracy\n# test to see if we can improve accuracy with a small change\nwith torch.no_grad():\n  weights[0] *= 1.0001\npreds = linear1(train_x)\nprint(f\"Average accuracy after updating the weights: {((preds&gt;0.0).float() == train_y).float().mean().item()}\")\n\n# there is no change because the change in weights is so small that (y_new - y_old) is very close to 0 ie.\n# the gradient is almost 0 everywhere\n\n# need to find a loss function which when our weights result in slightly better predictions produces a slightly better loss\n\nAverage accuracy after updating the weights: 0.36156824231147766\n\n\n\n\nLoss Function\n\n# Build a Loss Function\n# loss function receive predictions from the model about the images\n# the purpose of the loss function is to measure the difference between predicted values and true values ie the labels\ntrgts  = tensor([1,0,1])\nprds   = tensor([0.9, 0.4, 0.2])\n\n# first attempt at a loss function\ndef mnist_loss(predictions, targets):\n  # measures how distant each predictions is from 1 if it should be 1, how distant it is from 0 if it should be 0\n  # and takes the mean of all the distances\n    return torch.where(targets==1, 1-predictions, predictions).mean()\n\n# need a scalar for the final loss -&gt; the lower the loss value the better\n# indicates accurate predictions are more confident and when inaccurate predictions are less confident\nprint(f\"Test loss function: {mnist_loss(prds,trgts)}\")\n\n# issue with this loss function is that it assumes all predictions are between 0 and 1\n# sigmoid function always outputs a number between 0 and 1\ndef sigmoid(x):\n  return 1/(1+torch.exp(-x))\n\n# second attempt at a loss function using sigmoid\ndef mnist_loss_sigmoid(predictions, targets):\n    predictions = predictions.sigmoid()\n    return torch.where(targets==1, 1-predictions, predictions).mean()\n\nprint(f\"Test loss function with sigmoid: {mnist_loss_sigmoid(prds,trgts)}\")\n\nTest loss function: 0.43333330750465393\nTest loss function with sigmoid: 0.44596806168556213\n\n\n\n\nSGD + Mini Batches\n\n# SGD + Mini Batches\n# Optimization Step - updating the weights based on gradients\n# need to calculate loss over one or more data items\n# Solution: Calculate the average loss for a data items at a time (mini-batch)\n# Batch Size - number of items in mini batch\n\n# use fastai to build a dataloader object to shuffle data\n# randomly shuffle data on every epoch before creating mini batches\ncoll = range(15)\ndl = DataLoader(coll, batch_size=5, shuffle=True)\nprint(f\"Example of randomly generated mini-batch of batch size 5: {list(dl)}\")\n\nExample of randomly generated mini-batch of batch size 5: [tensor([12,  0,  7,  6,  9]), tensor([ 2, 13,  3, 14, 11]), tensor([ 4,  5,  1,  8, 10])]\n\n\n\n\nMNIST Model Training Loop using SGD\n\n# Build a training loop for a model\n# Initialize weights and bias randomly\nweights = init_params((28*28,1))\nbias = init_params(1)\n\n# Create DataLoader for the training data\ndl = DataLoader(dset, batch_size=256)\nxb,yb = first(dl)\nprint(f\"xb shape: {xb.shape}\")\nprint(f\"xb tensor rank: {len(xb.shape)}\")\nprint(f\"yb shape: {yb.shape}\")\nprint(f\"yb tensor rank: {len(yb.shape)}\")\n\n# Create DataLoader for the validation data\nvalid_dl = DataLoader(valid_dset, batch_size=256)\n\n# Create a Mini-Batch of batch size 4 for testing\nbatch = train_x[:4]\nprint(f\"batch shape: {batch.shape}\")\nprint(f\"batch tensor rank: {len(batch.shape)}\")\n\n# Create Predictions\n# preds = linear1(batch)\n# print(f\"predictions: {preds}\")\n\n# Measure loss\n# loss = mnist_loss_sigmoid(preds, train_y[:4])\n# print(f\"Loss: {loss}\")\n\n# Compute Gradients\n# loss.backward()\n# print(f\"weights gradient shape: {weights.grad.shape}\")\n# print(f\"Average of weight gradients: {weights.grad.mean()}\")\n# print(f\"bias gradient: {bias.grad}\")\n\n# function for calculating gradient\ndef calc_grad(xb, yb, model):\n    preds = model(xb)\n    loss = mnist_loss(preds, yb)\n    loss.backward()\n\nprint(f\"Test calculating gradients: {calc_grad(batch, train_y[:4], linear1)}\")\nprint(f\"Average of weight gradients: {weights.grad.mean()}\")\nprint(f\"bias gradient: {bias.grad}\")\n\n# loss.backward adds the gradients of loss to any gradients that are currently stored\n# so have to set the current gradients to 0 first\n\n# training loop for an epoch\ndef train_epoch(model, lr, params):\n    for xb,yb in dl:\n        calc_grad(xb, yb, model)\n        for p in params:\n            p.data -= p.grad*lr\n            p.grad.zero_()\n\n# check accuracy at this point\n# print(f\"Check Accuracy at this point: {(preds&gt;0.0).float() == train_y[:4]}\")\n\n# function for calculating validation accuracy\ndef batch_accuracy(xb, yb):\n    preds = xb.sigmoid()\n    correct = (preds&gt;0.5) == yb\n    return correct.float().mean()\n\nprint(f\"Testing batch accuracy: {batch_accuracy(linear1(batch), train_y[:4])}\")\n\n# put batches together to create a validation epoch\ndef validate_epoch(model):\n    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n    return round(torch.stack(accs).mean().item(), 4)\n\nprint(f\"Test validation epoch: {validate_epoch(linear1)}\")\n\n# train for 1 epoch and see if things improve\nlr = 1.\nparams = weights, bias\ntrain_epoch(linear1, lr, params)\nprint(f\"check if accuracy has improved from earlier: {validate_epoch(linear1)}\")\n\n# train for a few epochs\nfor i in range(20):\n    train_epoch(linear1, lr, params)\n    print(validate_epoch(linear1), end=' ')\n\nxb shape: torch.Size([256, 784])\nxb tensor rank: 2\nyb shape: torch.Size([256, 1])\nyb tensor rank: 2\nbatch shape: torch.Size([4, 784])\nbatch tensor rank: 2\nTest calculating gradients: None\nAverage of weight gradients: -0.15112045407295227\nbias gradient: tensor([-1.])\nTesting batch accuracy: 0.25\nTest validation epoch: 0.5065\ncheck if accuracy has improved from earlier: 0.946\n0.9534 0.9539 0.9534 0.9534 0.9529 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9539 0.9534 0.9534 0.9534 0.9534"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#pytorch-setup-for-sgd-pytorch-optimizer",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#pytorch-setup-for-sgd-pytorch-optimizer",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "PyTorch setup for SGD + Pytorch Optimizer",
    "text": "PyTorch setup for SGD + Pytorch Optimizer\n\n# Build SGD Functionality - PyTorch Optimizer\n\n# intialize weights and biases in a single pytorch class\nlinear_model = nn.Linear(28 * 28,1)\nw,b = linear_model.parameters()\nprint(f\"weights shape: {w.shape}\")\nprint(f\"weight tensor rank: {len(w.shape)}\")\nprint(f\"bias shape: {b.shape}\")\nprint(f\"bias tensor rank: {len(b.shape)}\")\n\n# Pytorch Optimizer Setup\nclass BasicOptim:\n    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n\n    def step(self, *args, **kwargs):\n        for p in self.params: p.data -= p.grad.data * self.lr\n\n    def zero_grad(self, *args, **kwargs):\n        for p in self.params: p.grad = None\n\nweights shape: torch.Size([1, 784])\nweight tensor rank: 2\nbias shape: torch.Size([1])\nbias tensor rank: 1\n\n\n\n# define training epoch function that use SGD\nopt = BasicOptim(linear_model.parameters(), lr)\n\ndef train_epoch(model):\n    for xb,yb in dl:\n        calc_grad(xb, yb, model)\n        opt.step()\n        opt.zero_grad()\n\n# check validation epoch\nprint(f\"Check accuracy after adding SGD: {validate_epoch(linear_model)}\")\n\n# Update Model Training\ndef train_model(model, epochs):\n    for i in range(epochs):\n        train_epoch(model)\n        print(validate_epoch(model), end=' ')\n\nprint(f\"Test training model: {train_model(linear_model, 20)}\")\n\nCheck accuracy after adding SGD: 0.5413\n0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 Test training model: None"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#train-mnist-model-using-fastai-library",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#train-mnist-model-using-fastai-library",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Train MNIST Model using FastAI Library",
    "text": "Train MNIST Model using FastAI Library\n\n# Modify Model Training Code with FastAI\n\n# define model information that uses SGD\n# linear_model = nn.Linear(28 * 28,1)\n# opt = SGD(linear_model.parameters(), lr)\n# train_model(linear_model, 20)\n\n# Define new DataLoaders\ndls = DataLoaders(dl, valid_dl)\n\n# Define a general purpose Learner class\nlearn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n                loss_func=mnist_loss_sigmoid, metrics=batch_accuracy)\n\n# Train Model with Learner.fit\nlearn.fit(10, lr=lr)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nbatch_accuracy\ntime\n\n\n\n\n0\n0.636952\n0.503232\n0.495584\n00:00\n\n\n1\n0.440637\n0.235429\n0.791462\n00:00\n\n\n2\n0.164770\n0.166296\n0.850834\n00:00\n\n\n3\n0.073948\n0.102109\n0.915604\n00:00\n\n\n4\n0.040399\n0.075625\n0.933268\n00:00\n\n\n5\n0.027231\n0.061010\n0.948479\n00:00\n\n\n6\n0.021780\n0.051817\n0.955839\n00:00\n\n\n7\n0.019325\n0.045666\n0.962709\n00:00\n\n\n8\n0.018058\n0.041325\n0.965162\n00:00\n\n\n9\n0.017283\n0.038114\n0.967615\n00:00"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#neural-networks",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#neural-networks",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Neural Networks",
    "text": "Neural Networks\nLinear classifiers are limited in what they can do. To handle more complex functions we need to add a nonlinear function between two linear classifiers. This is what defines a neural network.\n\n# define a simple neural network\n\n# randomly intialize weights and biases\nw1 = init_params((28 * 28,30))\nb1 = init_params(30)\nw2 = init_params((30,1))\nb2 = init_params(1)\n\n# def simple_net(xb):\n#     res = xb@w1 + b1\n#     # Rectified Linear Unit - RELU -&gt; replaces every negative number with 0\n#     res = res.max(tensor(0.0))\n#     res = res@w2 + b2\n#     return res\n\n\n# Pytorch version of a simple neural network\nsimple_net = nn.Sequential(\n    nn.Linear(28 * 28,30),\n    nn.ReLU(),\n    nn.Linear(30,1)\n)\n\n\n# Apply Simplenet to MNIST data\nlearn = Learner(dls, simple_net, opt_func=SGD,\n                loss_func=mnist_loss_sigmoid, metrics=batch_accuracy)\n\nlearn.fit(40, 0.1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nbatch_accuracy\ntime\n\n\n\n\n0\n0.282393\n0.406792\n0.505888\n00:00\n\n\n1\n0.134344\n0.215805\n0.817959\n00:00\n\n\n2\n0.076003\n0.111737\n0.918057\n00:00\n\n\n3\n0.051048\n0.076866\n0.940628\n00:01\n\n\n4\n0.039343\n0.060505\n0.956330\n00:00\n\n\n5\n0.033269\n0.051137\n0.962709\n00:00\n\n\n6\n0.029718\n0.045164\n0.965653\n00:00\n\n\n7\n0.027371\n0.041064\n0.966634\n00:00\n\n\n8\n0.025655\n0.038072\n0.969087\n00:00\n\n\n9\n0.024313\n0.035779\n0.970069\n00:00\n\n\n10\n0.023219\n0.033955\n0.972522\n00:00\n\n\n11\n0.022301\n0.032461\n0.973503\n00:00\n\n\n12\n0.021518\n0.031202\n0.976448\n00:00\n\n\n13\n0.020838\n0.030122\n0.976448\n00:00\n\n\n14\n0.020241\n0.029180\n0.976938\n00:00\n\n\n15\n0.019713\n0.028348\n0.977429\n00:00\n\n\n16\n0.019239\n0.027608\n0.977429\n00:00\n\n\n17\n0.018811\n0.026943\n0.978410\n00:00\n\n\n18\n0.018422\n0.026343\n0.978410\n00:00\n\n\n19\n0.018066\n0.025798\n0.978901\n00:00\n\n\n20\n0.017739\n0.025301\n0.978901\n00:00\n\n\n21\n0.017437\n0.024845\n0.979392\n00:00\n\n\n22\n0.017155\n0.024425\n0.979392\n00:00\n\n\n23\n0.016893\n0.024038\n0.979882\n00:00\n\n\n24\n0.016647\n0.023680\n0.980373\n00:00\n\n\n25\n0.016416\n0.023348\n0.980373\n00:00\n\n\n26\n0.016198\n0.023040\n0.980373\n00:00\n\n\n27\n0.015992\n0.022753\n0.980864\n00:00\n\n\n28\n0.015797\n0.022486\n0.981845\n00:00\n\n\n29\n0.015612\n0.022237\n0.982826\n00:00\n\n\n30\n0.015436\n0.022004\n0.982826\n00:00\n\n\n31\n0.015268\n0.021786\n0.982826\n00:00\n\n\n32\n0.015107\n0.021581\n0.983317\n00:00\n\n\n33\n0.014954\n0.021390\n0.982826\n00:00\n\n\n34\n0.014807\n0.021209\n0.982826\n00:00\n\n\n35\n0.014666\n0.021039\n0.982826\n00:00\n\n\n36\n0.014531\n0.020879\n0.982826\n00:00\n\n\n37\n0.014401\n0.020728\n0.982826\n00:00\n\n\n38\n0.014276\n0.020584\n0.982826\n00:00\n\n\n39\n0.014155\n0.020448\n0.982826\n00:00\n\n\n\n\n\n\n# visualize the accuracy of model using simplenet\n# y axis - accuracy\n# x-axis number of epochs\nplt.plot(L(learn.recorder.values).itemgot(2));\n\n\n\n\n\nprint(f\"Final Accuracy of model on the MNIST dataset: {learn.recorder.values[-1][2]}\")\n\nFinal Accuracy of model on the MNIST dataset: 0.982826292514801"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#going-deeper-into-deep-learning-neural-networks",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#going-deeper-into-deep-learning-neural-networks",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Going Deeper into Deep Learning + Neural Networks",
    "text": "Going Deeper into Deep Learning + Neural Networks\nThe following code below is an 18 layer resnet model with nearly 100% accuracy on the MNIST data. The above code was a simple neural network with 2 layers so the results of resnet-18 on this data show that accuracy improves as we add more layers. One thing to consider are the trade off’s mentioned by Jeremy in the lecture video\n\n# Going Deeper into Deep Learning + Neural Networks\ndls = ImageDataLoaders.from_folder(path)\nlearn = vision_learner(dls, resnet18, pretrained=False,\n                    loss_func=F.cross_entropy, metrics=accuracy)\nlearn.fit_one_cycle(1, 0.1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.089190\n0.011672\n0.998037\n00:18"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#terminology",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#terminology",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Terminology",
    "text": "Terminology\nActivations(Neural Network) - Numbers that are calculated (both by linear and non-linear layers)\nParameters(Neural Network) - Numbers that are randomly initialized, and optimized (that is, the numbers that define the model)\nAxis(Numpy), Dimensions(PyTorch Tensors) - For a matrix, the rows and columns define the axis\nTensor Rank - The number of dimensions in a tensor\nRank Zero Tensor - Scalar\nRank One Tensor - Vector\nRank Two Tensor - Matrix\nNonlinearity (Activation Function) - one type of layer in a neural network. Typically a neural network alternates between a linear layer and non-linear layer. Occasionally people refer to a single layer = linear layer + nonlinearity\nRelu - Function that returns 0 for negative numbers and doesn’t change positive numbers\nMini-Batch - A small group of inputs and labels gathered together in two arrays. A gradient desccent step is updated on this batch rather than a whole epoch\nForward Pass - Applying the model to some input and computing the predictions\nLoss - A value that represents how well (or bad) the model is doing Gradient - The derivative(slope) of the loss with respect to some parameter of the model\nBackward Pass - Computing the gradients of the loss with respect to all model parameters\nGradient Descent - Taking a step in the directions opposite to the gradients to make the model parameters a little bit better\nLearning Rate - The size of the step we take when applying SGD to update the parameters of the model. Usually a very tiny model"
  },
  {
    "objectID": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#resources",
    "href": "posts/fastai-lesson3/FASTAI_Lesson_3_V3.html#resources",
    "title": "FastAI Lesson 3: Neural Network Foundations",
    "section": "Resources",
    "text": "Resources\n\nFastAI Lesson 3\nFastAI Chapter 4, MNIST Basics\nHow Does a Neural Net Really Work\nWhich Image Models are Best\n3Blue1Brown Neural Networks\nAndrej Karpathy Neural Networks Zero to Hero\nUnderstanding Dimensions in PyTorch\nUnderstanding Numpy Axis\nPytorch Documentation\nfastai Documentation"
  },
  {
    "objectID": "posts/fastai-lesson0/index.html",
    "href": "posts/fastai-lesson0/index.html",
    "title": "FastAI Lesson 0: How to FastAI",
    "section": "",
    "text": "I’ve recently started FastAI Practical Deep Learning for Coders to learn about machine learning. To hold myself accountable and finish the course I am going to try to write a blog post for every video in the series starting with Lesson 0. By doing this my goal is to not only learn about deep learning and track my progress but reinforce my learning by trying to explain what I’ve learned for people new to machine learning like me. Lesson 0 isn’t officially presented in the course until Lesson 3 but it provides valuable advice for how to complete FastAI and actually learn how to write deep learning code.\nLesson 0 doesn’t have any code examples or notebooks but I took Jeremy’s advice about blogging and interacting with the community by setting up this Quarto blog as the Lesson 0 project. Lesson 0 was created in 2020 before Twitter became X and closed off to people who didn’t have an account. Since then, some of the ML community and other academic communities in CS have migrated to Discord , Mastodon, and Bluesky. I’d recommend checking out the FastAI Forums, FastAI Discord, and BlueSky."
  },
  {
    "objectID": "posts/fastai-lesson0/index.html#jeremy-howards-advice",
    "href": "posts/fastai-lesson0/index.html#jeremy-howards-advice",
    "title": "FastAI Lesson 0: How to FastAI",
    "section": "Jeremy Howard’s Advice",
    "text": "Jeremy Howard’s Advice\n\nCommit to finish the course\nTry to finish one really good project to show off what you’ve learned in the course\nShare and blog about your work"
  },
  {
    "objectID": "posts/fastai-lesson0/index.html#how-to-watch-a-fastai-lesson",
    "href": "posts/fastai-lesson0/index.html#how-to-watch-a-fastai-lesson",
    "title": "FastAI Lesson 0: How to FastAI",
    "section": "How to Watch A FastAI Lesson",
    "text": "How to Watch A FastAI Lesson\nThis advice was presented by Jeremy Howard in Lesson 0\n\nWatch FastAI Lecture\nRun notebooks and code presented in the lecture and experiment with code\nReproduce notebook from a clean notebook (Jeremy provides clean notebooks on github)\nRepeat with a different dataset (could be personal project)"
  },
  {
    "objectID": "posts/fastai-lesson0/index.html#resources",
    "href": "posts/fastai-lesson0/index.html#resources",
    "title": "FastAI Lesson 0: How to FastAI",
    "section": "Resources",
    "text": "Resources\n\nFastAI Lesson 0: How to FastAI\nChristine Mcleavey’s Blog\nQuarto\nBluesky"
  },
  {
    "objectID": "posts/fastai-lesson2/ModelDeployment.html",
    "href": "posts/fastai-lesson2/ModelDeployment.html",
    "title": "FastAI Lesson 2: Production",
    "section": "",
    "text": "Finally back! Had some deadlines and issues with gradio, kaggle, Firefox gtk rendering, quarto and jupyter but everything is working now. I’d like to give a shoutout to Kevin Liu for his help in getting up to speed with the updated gradio API. The example provided by Dr. Tanishq Abraham isn’t compatible with the updated version of Gradio so with Kevin’s notes on the gradio errors he ran into, I managed to get a model up on hugging face spaces with the new gradio syntax."
  },
  {
    "objectID": "posts/fastai-lesson2/ModelDeployment.html#announcments",
    "href": "posts/fastai-lesson2/ModelDeployment.html#announcments",
    "title": "FastAI Lesson 2: Production",
    "section": "",
    "text": "Finally back! Had some deadlines and issues with gradio, kaggle, Firefox gtk rendering, quarto and jupyter but everything is working now. I’d like to give a shoutout to Kevin Liu for his help in getting up to speed with the updated gradio API. The example provided by Dr. Tanishq Abraham isn’t compatible with the updated version of Gradio so with Kevin’s notes on the gradio errors he ran into, I managed to get a model up on hugging face spaces with the new gradio syntax."
  },
  {
    "objectID": "posts/fastai-lesson2/ModelDeployment.html#summary",
    "href": "posts/fastai-lesson2/ModelDeployment.html#summary",
    "title": "FastAI Lesson 2: Production",
    "section": "Summary",
    "text": "Summary\nIn this lesson, Jeremy walks through a bear classification model example and then spends most of the lesson focusing on how to deploy a model into production. By production, Jeremy is referring to using a model outside of a Jupyter notebook. This is very useful because it provides a way for designing a custom inviting interface for interacting with a trained model. The decision of what the user interface should look like comes down to project scope, goals and the people using the model.\nIf you’re a programmer, designer or learning deep learning like me, then it might be fun to hack around with javascript + the web to build a really nice interface. This can be a project in its own. The other group of people are data scientists, boss, team or people who need to interact with a prototype model ASAP. In that case, there are many handy python libraries and tools such as colab, altair, gradio and streamlit which provide a set of components that have been determined to be highly effective for rapid prototyping and sharing work on the web.\nIf you are looking to build a nice application I would maybe start with gradio or streamlit for prototyping but then work with a designer or web developer to build a nicer interface since I’ve learned from personal experience that python libraries that render javascript, html and css can be a debugging nightmare when creating interactive web user interfaces.\nUsing gradio reminded me a lot of using streamlit. I remember liking streamlit for its simplicity in creating components but its simplicity was also its curse because of the nightmare it created when a user wanted to customize components beyond what the library offered. I really liked the gradio version that was used by Tanishq in his example because the syntax was very explicit about what the arguments and parameters mean in a gradio function. What tripped me up in the new gradio syntax was how complicated it was to debug and set up components. Once I managed to grasp the pattern and syntax from the gradio documentation it was a smoother experience but if I was new to python it would have been very difficult. I try to avoid using streamlit when I can and I probably will do the same with gradio but the experience setting it up and deploying a model on hugging face spaces with a web interface was worth learning. I might come back to this lesson in the future once I finish the rest of the course to experiment with how to deploy a model."
  },
  {
    "objectID": "posts/fastai-lesson2/ModelDeployment.html#terminology",
    "href": "posts/fastai-lesson2/ModelDeployment.html#terminology",
    "title": "FastAI Lesson 2: Production",
    "section": "Terminology",
    "text": "Terminology\nObject Recognition - Computers can recognize what items are in an image at least as well as people can.\nObject Detection - Computers can recgonize where objects in an image are, and can highlight their locations and name each found object.\nSegmentation - A sub-area of object detection where every pixel is categorized on what kind of object it is part of\nData Augmentation - creating random variations of our input data such that they appear different but do not change the information in the data. Augmentation techniques for images include rotation, flipping, perspective warping, brightness, contrast."
  },
  {
    "objectID": "posts/fastai-lesson2/ModelDeployment.html#picasso-or-matisse-model",
    "href": "posts/fastai-lesson2/ModelDeployment.html#picasso-or-matisse-model",
    "title": "FastAI Lesson 2: Production",
    "section": "Picasso or Matisse Model",
    "text": "Picasso or Matisse Model\nInspired by Jeremy’s bear example, I changed my Picasso Braque example from my previous post and decided to instead try two different artists who weren’t so similar, in this case I chose Henri Matisse and Pablo Picasso. I trained the model the same way I did the Picasso Braques example but one thing I noticed was that some of the images seemed off for a duckduckgo search where duckduckgo would pull up a portrait of Picasso that didn’t look like it was from the same period I was searching. To try and fix this I tried to refresh the notebook runs multiple times until I got base images from actual Picasso and Matisse paintings. Similar to the Picasso Braque example, my Picasso predictions were off even though the label was correct but the Matisse ones were accurate.\nAfter I tried Picasso and Matisse paintings, I tried different Picasso artworks such as his sculptures and got correct classifications. One person I shared the model with tried uploading their family thanksgiving photo to see what happened and the model classified the photo as 97%. This was quite intriguing to me because I had not even trained the model on images other than picasso and matisse paintings. I’m only writing on Lesson 2, but Jeremy’s discussion about transfer learning in Lesson 1 and the book has me wondering if the classification of the 97% Picasso Thanksgiving photo is a bug and use case I didn’t consider or if it has something to do with the resnet-18 base model with how it picked up the color, line and movement.\n\n# install the latest libraries\n!pip install -Uqq fastai duckduckgo_search\n\n\nStep 1: Gather Data\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\n\n# helper function for searching for images\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n\nurls = search_images('Pablo Picasso Fauvism Paintings', max_images=1)\nurls[0]\n\nSearching for 'Pablo Picasso Fauvism Paintings'\n\n\n/usr/local/lib/python3.10/dist-packages/duckduckgo_search/compat.py:40: UserWarning: ddg_images is deprecated. Use DDGS().images() generator\n  warnings.warn(\"ddg_images is deprecated. Use DDGS().images() generator\")\n\n\n'https://i.pinimg.com/736x/b5/69/e1/b569e151ba0a9adf0136f5bdd7d4401b.jpg'\n\n\n\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\ndest = 'picasso.jpg'\ndownload_url(urls[0], dest, show_progress=False)\nim = Image.open(dest)\nim.to_thumb(256, 256)\n\n\n\n\n\ndownload_url(search_images('Henri Matisse Fauvism Paintings', max_images=1)[0],\n            'matisse.jpg',\n            show_progress=False)\nImage.open('matisse.jpg').to_thumb(256, 256)\n\nSearching for 'Henri Matisse Fauvism Paintings'\n\n\n/usr/local/lib/python3.10/dist-packages/duckduckgo_search/compat.py:40: UserWarning: ddg_images is deprecated. Use DDGS().images() generator\n  warnings.warn(\"ddg_images is deprecated. Use DDGS().images() generator\")\n\n\n\n\n\n\nsearches = 'Pablo Picasso', 'Henri Matisse'\npath = Path('picasso_or_matisse')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest,urls=search_images(f'{o} fauvism paintings'))\n    sleep(10) # sleep between searches to avoid spamming server\n    download_images(dest,urls=search_images(f'{o} still life fauvism paintings'))\n    sleep(10) # sleep between searches to avoid spamming server\n    download_images(dest,urls=search_images(f'{o} fauvism scenic paintings'))\n    sleep(10) # sleep between searches to avoid spamming server\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'Pablo Picasso fauvism paintings'\nSearching for 'Pablo Picasso still life fauvism paintings'\nSearching for 'Pablo Picasso fauvism scenic paintings'\nSearching for 'Henri Matisse fauvism paintings'\nSearching for 'Henri Matisse still life fauvism paintings'\nSearching for 'Henri Matisse fauvism scenic paintings'\n\n\n\n\nStep 2: Train Model\n\n# remove images that failed to download properly\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n0\n\n\n\n# split data into training set, validation set\ndls = DataBlock(\n    # specify input type(image), output type(category aka label)\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    # split data into 80% training data, and 20% validation data\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    # define the label\n    get_y=parent_label,\n    # standardize and resize all images to 192 x 192\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n# train a resnet model on the data\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.003311\n0.399668\n0.160377\n00:04\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.362328\n0.233523\n0.084906\n00:02\n\n\n1\n0.323960\n0.221361\n0.075472\n00:03\n\n\n2\n0.253416\n0.133047\n0.037736\n00:04\n\n\n3\n0.199347\n0.111490\n0.037736\n00:02\n\n\n\n\n\n\n\nStep 3: Test Model\n\nis_picasso,_,probs = learn.predict(PILImage.create('picasso.jpg'))\nprint(f\"This is a: {is_picasso}.\")\nprint(f\"Probability it's a picasso: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: Pablo Picasso.\nProbability it's a picasso: 0.0005\n\n\n\nis_matisse,_,probs = learn.predict(PILImage.create('matisse.jpg'))\nprint(f\"This is a: {is_matisse}.\")\nprint(f\"Probability it's a matisse: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: Henri Matisse.\nProbability it's a matisse: 0.9936\n\n\n\n\nStep 4: Save and Export Model\n\nlearn.export('model.pkl')"
  },
  {
    "objectID": "posts/fastai-lesson2/ModelDeployment.html#jeremy-howards-advice",
    "href": "posts/fastai-lesson2/ModelDeployment.html#jeremy-howards-advice",
    "title": "FastAI Lesson 2: Production",
    "section": "Jeremy Howard’s Advice",
    "text": "Jeremy Howard’s Advice\n\nTrain a model before data cleaning because it helps find data issues more quickly and easily."
  },
  {
    "objectID": "posts/fastai-lesson2/ModelDeployment.html#gradio-hugging-face-spaces",
    "href": "posts/fastai-lesson2/ModelDeployment.html#gradio-hugging-face-spaces",
    "title": "FastAI Lesson 2: Production",
    "section": "Gradio + Hugging Face Spaces",
    "text": "Gradio + Hugging Face Spaces\nThe following code was originally written by Dr. Tanishq Abraham and published in the blog post: Gradio + Hugging Face Spaces: A Tutorial. It was modified by me and Kevin Liu to work with the current version of the gradio api. Currently the code works on Hugging Face Spaces but may break in the future as gradio continues updating its api.\nMy recommendation to get gradio and Hugging Face Spaces working is to start off with Tanishq’s article and consult the gradio documentation to figure out the differences between the current version of the api and the version used in the article. I tried getting the pet classifier example working first before moving on to applying gradio to my Picasso Matisse Model which saved a lot of headache trying to figure out how git LFS and Hugging Face Spaces worked with my example.\n\nimport gradio as gr\nfrom fastai.vision.all import *\nimport skimage\n\n# load model \nlearn = load_learner('model.pkl') \n\n# define prediction function \nlabels = learn.dls.vocab\ndef predict(img):\n    img = PILImage.create(img)\n    pred,pred_idx,probs = learn.predict(img)\n    return {labels[i]: float(probs[i]) for i in range(len(labels))}\n\n# define interface structure \ntitle = \"Picasso or Mattise Classifier\"\ndescription = \"A classifier trained on Pablo Picasso and Henri Mattise paintings with fast.ai.\"\nexamples = ['picasso.jpg', 'matisse.jpg']\ngr.Interface(fn=predict, inputs=[gr.Image(type=\"pil\")], outputs=gr.Label(num_top_classes=3)).launch(share=True)\n\n# interpretation = 'default'\n# enable_queue = True \n\n\n# def greet(name):\n#     return \"Hello \" + name + \"!!\"\n\n# iface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n# iface.launch()"
  },
  {
    "objectID": "posts/fastai-lesson2/ModelDeployment.html#resources",
    "href": "posts/fastai-lesson2/ModelDeployment.html#resources",
    "title": "FastAI Lesson 2: Production",
    "section": "Resources",
    "text": "Resources\n\nPicasso or Mattise Gradio + Hugging Face Spaces\nFastAI Lesson 2\nFastAI Chapter 2, Production\nHugging Face Spaces\nGradio\nHow to Set Up an SSH Key(GitHub, Hugging Face Spaces)\nGradio + Hugging Face Spaces: A Tutorial\nGradio Documentation\nfastai Documentation"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "FastAI Lesson 3: Neural Network Foundations\n\n\n\n\n\n\n\nlearning\n\n\nfastai\n\n\ndeep learning\n\n\n\n\nFastAI Lesson 3 Notes\n\n\n\n\n\n\nDec 18, 2023\n\n\nPranav Rajan\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Lesson 2: Production\n\n\n\n\n\n\n\nlearning\n\n\nfastai\n\n\ndeep learning\n\n\n\n\nFastAI Lesson 2 Notes\n\n\n\n\n\n\nNov 30, 2023\n\n\nPranav Rajan\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Lesson 1: Getting Started\n\n\n\n\n\n\n\nlearning\n\n\nfastai\n\n\ndeep learning\n\n\n\n\nFastAI Lesson 1 Notes\n\n\n\n\n\n\nNov 21, 2023\n\n\nPranav Rajan\n\n\n\n\n\n\n  \n\n\n\n\nFastAI Lesson 0: How to FastAI\n\n\n\n\n\n\n\nlearning\n\n\nfastai\n\n\ndeep learning\n\n\n\n\nFastAI Lesson 0 Notes\n\n\n\n\n\n\nNov 19, 2023\n\n\nPranav Rajan\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\nFirst Blog Post\n\n\n\n\n\n\nNov 19, 2023\n\n\nPranav Rajan\n\n\n\n\n\n\nNo matching items"
  }
]