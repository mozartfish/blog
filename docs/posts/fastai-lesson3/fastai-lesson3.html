<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Pranav Rajan">
<meta name="dcterms.date" content="2023-12-18">
<meta name="description" content="FastAI Lesson 3 Notes">

<title>Pranav Rajan’s Blog - FastAI Lesson 3: Neural Network Foundations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Pranav Rajan’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mozartfish" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">FastAI Lesson 3: Neural Network Foundations</h1>
                  <div>
        <div class="description">
          FastAI Lesson 3 Notes
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">learning</div>
                <div class="quarto-category">fastai</div>
                <div class="quarto-category">deep learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Pranav Rajan </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 18, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#announcements" id="toc-announcements" class="nav-link active" data-scroll-target="#announcements">Announcements</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements">Acknowledgements</a></li>
  <li><a href="#summary---fastai-lesson-3-video" id="toc-summary---fastai-lesson-3-video" class="nav-link" data-scroll-target="#summary---fastai-lesson-3-video">Summary - FastAI Lesson 3 Video</a></li>
  <li><a href="#summary-fastai-chapter-4" id="toc-summary-fastai-chapter-4" class="nav-link" data-scroll-target="#summary-fastai-chapter-4">Summary FastAI Chapter 4</a></li>
  <li><a href="#jeremy-howards-advice" id="toc-jeremy-howards-advice" class="nav-link" data-scroll-target="#jeremy-howards-advice">Jeremy Howard’s Advice</a></li>
  <li><a href="#mnist-dataset" id="toc-mnist-dataset" class="nav-link" data-scroll-target="#mnist-dataset">MNIST Dataset</a></li>
  <li><a href="#representing-images-as-numbers" id="toc-representing-images-as-numbers" class="nav-link" data-scroll-target="#representing-images-as-numbers">Representing Images as Numbers</a></li>
  <li><a href="#baseline-model-pixel-similarity" id="toc-baseline-model-pixel-similarity" class="nav-link" data-scroll-target="#baseline-model-pixel-similarity">Baseline Model: Pixel Similarity</a></li>
  <li><a href="#measuring-distance" id="toc-measuring-distance" class="nav-link" data-scroll-target="#measuring-distance">Measuring Distance</a></li>
  <li><a href="#pytorch-numpy" id="toc-pytorch-numpy" class="nav-link" data-scroll-target="#pytorch-numpy">Pytorch + Numpy</a></li>
  <li><a href="#computing-metrics" id="toc-computing-metrics" class="nav-link" data-scroll-target="#computing-metrics">Computing Metrics</a></li>
  <li><a href="#stochastic-gradient-descent" id="toc-stochastic-gradient-descent" class="nav-link" data-scroll-target="#stochastic-gradient-descent">Stochastic Gradient Descent</a>
  <ul class="collapse">
  <li><a href="#stochastic-gradient-descent-steps-for-an-image-classifier" id="toc-stochastic-gradient-descent-steps-for-an-image-classifier" class="nav-link" data-scroll-target="#stochastic-gradient-descent-steps-for-an-image-classifier">Stochastic Gradient Descent Steps for an Image Classifier</a></li>
  </ul></li>
  <li><a href="#building-the-mnist-image-classifier" id="toc-building-the-mnist-image-classifier" class="nav-link" data-scroll-target="#building-the-mnist-image-classifier">Building the MNIST Image Classifier</a>
  <ul class="collapse">
  <li><a href="#training-dataset" id="toc-training-dataset" class="nav-link" data-scroll-target="#training-dataset">Training Dataset</a></li>
  <li><a href="#validation-dataset" id="toc-validation-dataset" class="nav-link" data-scroll-target="#validation-dataset">Validation Dataset</a></li>
  <li><a href="#initialize-model-weights" id="toc-initialize-model-weights" class="nav-link" data-scroll-target="#initialize-model-weights">Initialize Model Weights</a></li>
  <li><a href="#linear-classifier" id="toc-linear-classifier" class="nav-link" data-scroll-target="#linear-classifier">Linear Classifier</a></li>
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function">Loss Function</a></li>
  <li><a href="#sgd-mini-batches" id="toc-sgd-mini-batches" class="nav-link" data-scroll-target="#sgd-mini-batches">SGD + Mini Batches</a></li>
  <li><a href="#mnist-model-training-loop-using-sgd" id="toc-mnist-model-training-loop-using-sgd" class="nav-link" data-scroll-target="#mnist-model-training-loop-using-sgd">MNIST Model Training Loop using SGD</a></li>
  </ul></li>
  <li><a href="#pytorch-setup-for-sgd-pytorch-optimizer" id="toc-pytorch-setup-for-sgd-pytorch-optimizer" class="nav-link" data-scroll-target="#pytorch-setup-for-sgd-pytorch-optimizer">PyTorch setup for SGD + Pytorch Optimizer</a></li>
  <li><a href="#train-mnist-model-using-fastai-library" id="toc-train-mnist-model-using-fastai-library" class="nav-link" data-scroll-target="#train-mnist-model-using-fastai-library">Train MNIST Model using FastAI Library</a></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks">Neural Networks</a></li>
  <li><a href="#going-deeper-into-deep-learning-neural-networks" id="toc-going-deeper-into-deep-learning-neural-networks" class="nav-link" data-scroll-target="#going-deeper-into-deep-learning-neural-networks">Going Deeper into Deep Learning + Neural Networks</a></li>
  <li><a href="#terminology" id="toc-terminology" class="nav-link" data-scroll-target="#terminology">Terminology</a></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources">Resources</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="announcements" class="level2">
<h2 class="anchored" data-anchor-id="announcements">Announcements</h2>
<p>Finally back after a long hiatus. I took a break from posting and FASTAI to try Advent of Code and get back to interview prep but I’m back. Normally I only write a single summary for a blog post but this time I’m writing two summaries because Chapter 4 of the book goes deeper into the foundations of neural networks than the lecture video.</p>
</section>
<section id="acknowledgements" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgements">Acknowledgements</h2>
<p>All of this code was written by Jeremy Howard and the authors of the FastAI book. My modification to their code was adding print statements and comments to understand what each line of code was doing.</p>
</section>
<section id="summary---fastai-lesson-3-video" class="level2">
<h2 class="anchored" data-anchor-id="summary---fastai-lesson-3-video">Summary - FastAI Lesson 3 Video</h2>
<p>In this lesson, Jeremy gives a high level overview of pytorch, gradient descent and the evolution of models. Most of the video focuses on approximating a quadratic equation and building the intuition towards how a neural network works. Towards the end of the video, Jeremy introduces the Titanic dataset and how to do some basic modeling with excel.</p>
</section>
<section id="summary-fastai-chapter-4" class="level2">
<h2 class="anchored" data-anchor-id="summary-fastai-chapter-4">Summary FastAI Chapter 4</h2>
<p>In Chapter 4, the FastAI book authors use the MNIST dataset as a case study to understand how pytorch and the fastai library work under the hood. I found this chapter to be a mind bender because I struggled to wrap my head around the concept of a tensor and the kinds of operations you can do on a tensor. Another concept I struggled with was the meaning of rank and dimension of tensors which are not the same as the meaning of rank and dimension in linear algebra and physics (will go more into this later). By the end of this chapter, I understood the following concepts:</p>
<ul>
<li>what a tensor represents and performing operations on a tensor</li>
<li>how to set up a classifier using pytorch</li>
<li>how a training loop, optimizer, batch work in pytorch and fastai</li>
<li>the operations and functions that fastai provides a wrapper on top of</li>
</ul>
<p>I do agree with Jeremy that this book chapter might scare people away because the jargon combined with the mathematical concepts but its definitely worth spending a few days getting through since you develop a deeper understanding of pytorch and the deep learning process.</p>
</section>
<section id="jeremy-howards-advice" class="level2">
<h2 class="anchored" data-anchor-id="jeremy-howards-advice">Jeremy Howard’s Advice</h2>
<p>Jeremy provides some really good insights and advice in the lecture video not captured in the book or kaggle notebooks. This is my summary of the advice:</p>
<ul>
<li><p>Model: Mathematical function consisting of a Matrix Multiply operation + nonlinearity (RELU, Sigmoid etc)</p></li>
<li><p>Things to thing about when picking a class of model for a problem we’re trying to solve:</p>
<ol type="1">
<li>How fast is the model</li>
<li>How much memory does it consume</li>
<li>How accurate is it</li>
</ol></li>
<li><p>Models fit functions to data and try to recognize patterns in data that we give it</p></li>
</ul>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load libraries and imports</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>Uqq fastai duckduckgo_search</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> partial</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># import fastai libraries</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># update grayscale colormap for matplotlib</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>matplotlib.rc(<span class="st">'image'</span>, cmap<span class="op">=</span><span class="st">'Greys'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="mnist-dataset" class="level2">
<h2 class="anchored" data-anchor-id="mnist-dataset">MNIST Dataset</h2>
<p>To show how neural networks work, the FastAI authors use the MNIST dataset as a case study. MNIST is a dataset containing handwritten digits collected by NIST (National Institute of Standards and Technology) and turned into dataset by Yann Lecun and his colleagues. For more information about Lecun and MNIST I would recommend reading the book chapter.</p>
<p>The MNIST dataset follows traditional machine learning dataset layouts: Training Data and Validation Data each containing images associated with a particular digit between 0-9.</p>
<div class="cell" data-outputid="0ec884f7-a259-41ae-ff88-afcd8bd7f2ce" data-execution_count="41">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># LOAD MNIST DATA</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.MNIST_SAMPLE)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>Path.BASE_PATH <span class="op">=</span> path</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Contents of MNIST DATA: </span><span class="sc">{</span>path<span class="sc">.</span>ls()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># MNIST Training Data</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MNIST Training Data Directory Contents: </span><span class="sc">{</span>(path<span class="op">/</span><span class="st">'train'</span>)<span class="sc">.</span>ls()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># MNIST Training Data for 3s and 7s in sorted order</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>threes <span class="op">=</span> (path<span class="op">/</span><span class="st">'train'</span><span class="op">/</span><span class="st">'3'</span>).ls().<span class="bu">sorted</span>()</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>sevens <span class="op">=</span> (path<span class="op">/</span><span class="st">'train'</span><span class="op">/</span><span class="st">'7'</span>).ls().<span class="bu">sorted</span>()</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Sorted Training Data for 3: {threes}")</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Training Data Example</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>im3_path <span class="op">=</span> threes[<span class="dv">1</span>]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>im3 <span class="op">=</span> Image.<span class="bu">open</span>(im3_path)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test Image of 3 from 3 training data set"</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>im3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Contents of MNIST DATA: [Path('train'), Path('valid'), Path('labels.csv')]
MNIST Training Data Directory Contents: [Path('train/7'), Path('train/3')]
Test Image of 3 from 3 training data set</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="41">
<p><img src="fastai-lesson3_files/figure-html/cell-3-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="representing-images-as-numbers" class="level2">
<h2 class="anchored" data-anchor-id="representing-images-as-numbers">Representing Images as Numbers</h2>
<p>Images are represented on computers as an array of pixels where each index contains a list of 3 numbers between 0-255 corresponding to a particular color according to RGB. Assembling all of these colors together we get an image.</p>
<p>The MNIST images are represented differently: each index in the image array contains a number between 0-255 where 0 represents white and 255 black. All other values between 0-255 represent a different shade of gray. A unique digit image in the MNIST data is then defined by the black and gray pixels that together outline and define the digit. The size of an image in the MNIST data is 28 x 28 which is 784 pixels in the Image Array.</p>
<p>In the following examples, [4:10, 4:10] means the following: request rows from index 4 (included) to 10(not included) and the same for the columns. Numpy and Pytorch index from top to bottom and left to right.</p>
<p>In the image slice below, we select a part of the digit with just the top part and then color code the slice based on the values in the slice with their mapping in the gray scale (0-255) where 0 represents white and 255 black.</p>
<div class="cell" data-outputid="bdbaca93-1fb1-4be9-e438-f781d92b2b1d" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MNIST image dimensions are 28 x 28 = 784 pixel array</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"im3 represented as an array of numbers using numpy array"</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>array(im3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>im3 represented as an array of numbers using numpy array</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254,
        255, 254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234,
        196, 253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,
          4,  10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,
          0,   0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,
          0,  43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0, 249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101,
        223, 253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253,
        253, 253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253,
        253, 253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,
         98, 208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,  98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42,
        150, 252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240,
        253, 253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253,
        253, 197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,
         67,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0]], dtype=uint8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="248d1938-6496-4b0e-b5e5-20d61e9d2586" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Slice of im3</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># [4:10, 4:10] - get rows and columns starting from 4(included) to 10 (excluded)</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Numpy Array representation</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>array(im3)[<span class="dv">4</span>:<span class="dv">10</span>,<span class="dv">4</span>:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>array([[  0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  29],
       [  0,   0,   0,  48, 166, 224],
       [  0,  93, 244, 249, 253, 187],
       [  0, 107, 253, 253, 230,  48],
       [  0,   3,  20,  20,  15,   0]], dtype=uint8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="71ebd6b7-d056-42e3-ef9a-0340934ef9bd" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MNIST image dimensions are 28 x 28 = 784 pixel array</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"im3 represented as an array of numbers using tensors"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>tensor(im3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>im3 represented as an array of numbers using tensors</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254, 255,
         254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234, 196,
         253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,   4,
          10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,   0,
           0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,   0,
          43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101, 223,
         253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253, 253,
         253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253, 253,
         253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,  98,
         208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 150,
         252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240, 253,
         253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253, 253,
         197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,  67,
           1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],
       dtype=torch.uint8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="2c8afa5e-3feb-4003-82b6-b709efcb2ee4" data-execution_count="6">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Slice of im3</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># [4:10, 4:10] - get rows and columns starting from 4(included) to 10 (excluded)</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor representation</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>tensor(im3)[<span class="dv">4</span>:<span class="dv">10</span>, <span class="dv">4</span>:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[  0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,  29],
        [  0,   0,   0,  48, 166, 224],
        [  0,  93, 244, 249, 253, 187],
        [  0, 107, 253, 253, 230,  48],
        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="a7c0d0d8-b2a0-4bf1-a913-4bb6d67e42b4" data-execution_count="7">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># slice data to obtain the top part of the number and color code data to show digit outline</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># slice data rows: 4(included)-15(excluded)</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># slice data columns: 4(included)-22(excluded)</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>im3_t <span class="op">=</span> tensor(im3)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(im3_t[<span class="dv">4</span>:<span class="dv">15</span>,<span class="dv">4</span>:<span class="dv">22</span>])</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>df.style.set_properties(<span class="op">**</span>{<span class="st">'font-size'</span>:<span class="st">'6pt'</span>}).background_gradient(<span class="st">'Greys'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">


<table id="T_9106b" class="dataframe table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_9106b_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">0</th>
<th id="T_9106b_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">1</th>
<th id="T_9106b_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">2</th>
<th id="T_9106b_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">3</th>
<th id="T_9106b_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">4</th>
<th id="T_9106b_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">5</th>
<th id="T_9106b_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">6</th>
<th id="T_9106b_level0_col7" class="col_heading level0 col7" data-quarto-table-cell-role="th">7</th>
<th id="T_9106b_level0_col8" class="col_heading level0 col8" data-quarto-table-cell-role="th">8</th>
<th id="T_9106b_level0_col9" class="col_heading level0 col9" data-quarto-table-cell-role="th">9</th>
<th id="T_9106b_level0_col10" class="col_heading level0 col10" data-quarto-table-cell-role="th">10</th>
<th id="T_9106b_level0_col11" class="col_heading level0 col11" data-quarto-table-cell-role="th">11</th>
<th id="T_9106b_level0_col12" class="col_heading level0 col12" data-quarto-table-cell-role="th">12</th>
<th id="T_9106b_level0_col13" class="col_heading level0 col13" data-quarto-table-cell-role="th">13</th>
<th id="T_9106b_level0_col14" class="col_heading level0 col14" data-quarto-table-cell-role="th">14</th>
<th id="T_9106b_level0_col15" class="col_heading level0 col15" data-quarto-table-cell-role="th">15</th>
<th id="T_9106b_level0_col16" class="col_heading level0 col16" data-quarto-table-cell-role="th">16</th>
<th id="T_9106b_level0_col17" class="col_heading level0 col17" data-quarto-table-cell-role="th">17</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_9106b_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_9106b_row0_col0" class="data row0 col0">0</td>
<td id="T_9106b_row0_col1" class="data row0 col1">0</td>
<td id="T_9106b_row0_col2" class="data row0 col2">0</td>
<td id="T_9106b_row0_col3" class="data row0 col3">0</td>
<td id="T_9106b_row0_col4" class="data row0 col4">0</td>
<td id="T_9106b_row0_col5" class="data row0 col5">0</td>
<td id="T_9106b_row0_col6" class="data row0 col6">0</td>
<td id="T_9106b_row0_col7" class="data row0 col7">0</td>
<td id="T_9106b_row0_col8" class="data row0 col8">0</td>
<td id="T_9106b_row0_col9" class="data row0 col9">0</td>
<td id="T_9106b_row0_col10" class="data row0 col10">0</td>
<td id="T_9106b_row0_col11" class="data row0 col11">0</td>
<td id="T_9106b_row0_col12" class="data row0 col12">0</td>
<td id="T_9106b_row0_col13" class="data row0 col13">0</td>
<td id="T_9106b_row0_col14" class="data row0 col14">0</td>
<td id="T_9106b_row0_col15" class="data row0 col15">0</td>
<td id="T_9106b_row0_col16" class="data row0 col16">0</td>
<td id="T_9106b_row0_col17" class="data row0 col17">0</td>
</tr>
<tr class="even">
<td id="T_9106b_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_9106b_row1_col0" class="data row1 col0">0</td>
<td id="T_9106b_row1_col1" class="data row1 col1">0</td>
<td id="T_9106b_row1_col2" class="data row1 col2">0</td>
<td id="T_9106b_row1_col3" class="data row1 col3">0</td>
<td id="T_9106b_row1_col4" class="data row1 col4">0</td>
<td id="T_9106b_row1_col5" class="data row1 col5">29</td>
<td id="T_9106b_row1_col6" class="data row1 col6">150</td>
<td id="T_9106b_row1_col7" class="data row1 col7">195</td>
<td id="T_9106b_row1_col8" class="data row1 col8">254</td>
<td id="T_9106b_row1_col9" class="data row1 col9">255</td>
<td id="T_9106b_row1_col10" class="data row1 col10">254</td>
<td id="T_9106b_row1_col11" class="data row1 col11">176</td>
<td id="T_9106b_row1_col12" class="data row1 col12">193</td>
<td id="T_9106b_row1_col13" class="data row1 col13">150</td>
<td id="T_9106b_row1_col14" class="data row1 col14">96</td>
<td id="T_9106b_row1_col15" class="data row1 col15">0</td>
<td id="T_9106b_row1_col16" class="data row1 col16">0</td>
<td id="T_9106b_row1_col17" class="data row1 col17">0</td>
</tr>
<tr class="odd">
<td id="T_9106b_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_9106b_row2_col0" class="data row2 col0">0</td>
<td id="T_9106b_row2_col1" class="data row2 col1">0</td>
<td id="T_9106b_row2_col2" class="data row2 col2">0</td>
<td id="T_9106b_row2_col3" class="data row2 col3">48</td>
<td id="T_9106b_row2_col4" class="data row2 col4">166</td>
<td id="T_9106b_row2_col5" class="data row2 col5">224</td>
<td id="T_9106b_row2_col6" class="data row2 col6">253</td>
<td id="T_9106b_row2_col7" class="data row2 col7">253</td>
<td id="T_9106b_row2_col8" class="data row2 col8">234</td>
<td id="T_9106b_row2_col9" class="data row2 col9">196</td>
<td id="T_9106b_row2_col10" class="data row2 col10">253</td>
<td id="T_9106b_row2_col11" class="data row2 col11">253</td>
<td id="T_9106b_row2_col12" class="data row2 col12">253</td>
<td id="T_9106b_row2_col13" class="data row2 col13">253</td>
<td id="T_9106b_row2_col14" class="data row2 col14">233</td>
<td id="T_9106b_row2_col15" class="data row2 col15">0</td>
<td id="T_9106b_row2_col16" class="data row2 col16">0</td>
<td id="T_9106b_row2_col17" class="data row2 col17">0</td>
</tr>
<tr class="even">
<td id="T_9106b_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_9106b_row3_col0" class="data row3 col0">0</td>
<td id="T_9106b_row3_col1" class="data row3 col1">93</td>
<td id="T_9106b_row3_col2" class="data row3 col2">244</td>
<td id="T_9106b_row3_col3" class="data row3 col3">249</td>
<td id="T_9106b_row3_col4" class="data row3 col4">253</td>
<td id="T_9106b_row3_col5" class="data row3 col5">187</td>
<td id="T_9106b_row3_col6" class="data row3 col6">46</td>
<td id="T_9106b_row3_col7" class="data row3 col7">10</td>
<td id="T_9106b_row3_col8" class="data row3 col8">8</td>
<td id="T_9106b_row3_col9" class="data row3 col9">4</td>
<td id="T_9106b_row3_col10" class="data row3 col10">10</td>
<td id="T_9106b_row3_col11" class="data row3 col11">194</td>
<td id="T_9106b_row3_col12" class="data row3 col12">253</td>
<td id="T_9106b_row3_col13" class="data row3 col13">253</td>
<td id="T_9106b_row3_col14" class="data row3 col14">233</td>
<td id="T_9106b_row3_col15" class="data row3 col15">0</td>
<td id="T_9106b_row3_col16" class="data row3 col16">0</td>
<td id="T_9106b_row3_col17" class="data row3 col17">0</td>
</tr>
<tr class="odd">
<td id="T_9106b_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_9106b_row4_col0" class="data row4 col0">0</td>
<td id="T_9106b_row4_col1" class="data row4 col1">107</td>
<td id="T_9106b_row4_col2" class="data row4 col2">253</td>
<td id="T_9106b_row4_col3" class="data row4 col3">253</td>
<td id="T_9106b_row4_col4" class="data row4 col4">230</td>
<td id="T_9106b_row4_col5" class="data row4 col5">48</td>
<td id="T_9106b_row4_col6" class="data row4 col6">0</td>
<td id="T_9106b_row4_col7" class="data row4 col7">0</td>
<td id="T_9106b_row4_col8" class="data row4 col8">0</td>
<td id="T_9106b_row4_col9" class="data row4 col9">0</td>
<td id="T_9106b_row4_col10" class="data row4 col10">0</td>
<td id="T_9106b_row4_col11" class="data row4 col11">192</td>
<td id="T_9106b_row4_col12" class="data row4 col12">253</td>
<td id="T_9106b_row4_col13" class="data row4 col13">253</td>
<td id="T_9106b_row4_col14" class="data row4 col14">156</td>
<td id="T_9106b_row4_col15" class="data row4 col15">0</td>
<td id="T_9106b_row4_col16" class="data row4 col16">0</td>
<td id="T_9106b_row4_col17" class="data row4 col17">0</td>
</tr>
<tr class="even">
<td id="T_9106b_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_9106b_row5_col0" class="data row5 col0">0</td>
<td id="T_9106b_row5_col1" class="data row5 col1">3</td>
<td id="T_9106b_row5_col2" class="data row5 col2">20</td>
<td id="T_9106b_row5_col3" class="data row5 col3">20</td>
<td id="T_9106b_row5_col4" class="data row5 col4">15</td>
<td id="T_9106b_row5_col5" class="data row5 col5">0</td>
<td id="T_9106b_row5_col6" class="data row5 col6">0</td>
<td id="T_9106b_row5_col7" class="data row5 col7">0</td>
<td id="T_9106b_row5_col8" class="data row5 col8">0</td>
<td id="T_9106b_row5_col9" class="data row5 col9">0</td>
<td id="T_9106b_row5_col10" class="data row5 col10">43</td>
<td id="T_9106b_row5_col11" class="data row5 col11">224</td>
<td id="T_9106b_row5_col12" class="data row5 col12">253</td>
<td id="T_9106b_row5_col13" class="data row5 col13">245</td>
<td id="T_9106b_row5_col14" class="data row5 col14">74</td>
<td id="T_9106b_row5_col15" class="data row5 col15">0</td>
<td id="T_9106b_row5_col16" class="data row5 col16">0</td>
<td id="T_9106b_row5_col17" class="data row5 col17">0</td>
</tr>
<tr class="odd">
<td id="T_9106b_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_9106b_row6_col0" class="data row6 col0">0</td>
<td id="T_9106b_row6_col1" class="data row6 col1">0</td>
<td id="T_9106b_row6_col2" class="data row6 col2">0</td>
<td id="T_9106b_row6_col3" class="data row6 col3">0</td>
<td id="T_9106b_row6_col4" class="data row6 col4">0</td>
<td id="T_9106b_row6_col5" class="data row6 col5">0</td>
<td id="T_9106b_row6_col6" class="data row6 col6">0</td>
<td id="T_9106b_row6_col7" class="data row6 col7">0</td>
<td id="T_9106b_row6_col8" class="data row6 col8">0</td>
<td id="T_9106b_row6_col9" class="data row6 col9">0</td>
<td id="T_9106b_row6_col10" class="data row6 col10">249</td>
<td id="T_9106b_row6_col11" class="data row6 col11">253</td>
<td id="T_9106b_row6_col12" class="data row6 col12">245</td>
<td id="T_9106b_row6_col13" class="data row6 col13">126</td>
<td id="T_9106b_row6_col14" class="data row6 col14">0</td>
<td id="T_9106b_row6_col15" class="data row6 col15">0</td>
<td id="T_9106b_row6_col16" class="data row6 col16">0</td>
<td id="T_9106b_row6_col17" class="data row6 col17">0</td>
</tr>
<tr class="even">
<td id="T_9106b_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_9106b_row7_col0" class="data row7 col0">0</td>
<td id="T_9106b_row7_col1" class="data row7 col1">0</td>
<td id="T_9106b_row7_col2" class="data row7 col2">0</td>
<td id="T_9106b_row7_col3" class="data row7 col3">0</td>
<td id="T_9106b_row7_col4" class="data row7 col4">0</td>
<td id="T_9106b_row7_col5" class="data row7 col5">0</td>
<td id="T_9106b_row7_col6" class="data row7 col6">0</td>
<td id="T_9106b_row7_col7" class="data row7 col7">14</td>
<td id="T_9106b_row7_col8" class="data row7 col8">101</td>
<td id="T_9106b_row7_col9" class="data row7 col9">223</td>
<td id="T_9106b_row7_col10" class="data row7 col10">253</td>
<td id="T_9106b_row7_col11" class="data row7 col11">248</td>
<td id="T_9106b_row7_col12" class="data row7 col12">124</td>
<td id="T_9106b_row7_col13" class="data row7 col13">0</td>
<td id="T_9106b_row7_col14" class="data row7 col14">0</td>
<td id="T_9106b_row7_col15" class="data row7 col15">0</td>
<td id="T_9106b_row7_col16" class="data row7 col16">0</td>
<td id="T_9106b_row7_col17" class="data row7 col17">0</td>
</tr>
<tr class="odd">
<td id="T_9106b_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_9106b_row8_col0" class="data row8 col0">0</td>
<td id="T_9106b_row8_col1" class="data row8 col1">0</td>
<td id="T_9106b_row8_col2" class="data row8 col2">0</td>
<td id="T_9106b_row8_col3" class="data row8 col3">0</td>
<td id="T_9106b_row8_col4" class="data row8 col4">0</td>
<td id="T_9106b_row8_col5" class="data row8 col5">11</td>
<td id="T_9106b_row8_col6" class="data row8 col6">166</td>
<td id="T_9106b_row8_col7" class="data row8 col7">239</td>
<td id="T_9106b_row8_col8" class="data row8 col8">253</td>
<td id="T_9106b_row8_col9" class="data row8 col9">253</td>
<td id="T_9106b_row8_col10" class="data row8 col10">253</td>
<td id="T_9106b_row8_col11" class="data row8 col11">187</td>
<td id="T_9106b_row8_col12" class="data row8 col12">30</td>
<td id="T_9106b_row8_col13" class="data row8 col13">0</td>
<td id="T_9106b_row8_col14" class="data row8 col14">0</td>
<td id="T_9106b_row8_col15" class="data row8 col15">0</td>
<td id="T_9106b_row8_col16" class="data row8 col16">0</td>
<td id="T_9106b_row8_col17" class="data row8 col17">0</td>
</tr>
<tr class="even">
<td id="T_9106b_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_9106b_row9_col0" class="data row9 col0">0</td>
<td id="T_9106b_row9_col1" class="data row9 col1">0</td>
<td id="T_9106b_row9_col2" class="data row9 col2">0</td>
<td id="T_9106b_row9_col3" class="data row9 col3">0</td>
<td id="T_9106b_row9_col4" class="data row9 col4">0</td>
<td id="T_9106b_row9_col5" class="data row9 col5">16</td>
<td id="T_9106b_row9_col6" class="data row9 col6">248</td>
<td id="T_9106b_row9_col7" class="data row9 col7">250</td>
<td id="T_9106b_row9_col8" class="data row9 col8">253</td>
<td id="T_9106b_row9_col9" class="data row9 col9">253</td>
<td id="T_9106b_row9_col10" class="data row9 col10">253</td>
<td id="T_9106b_row9_col11" class="data row9 col11">253</td>
<td id="T_9106b_row9_col12" class="data row9 col12">232</td>
<td id="T_9106b_row9_col13" class="data row9 col13">213</td>
<td id="T_9106b_row9_col14" class="data row9 col14">111</td>
<td id="T_9106b_row9_col15" class="data row9 col15">2</td>
<td id="T_9106b_row9_col16" class="data row9 col16">0</td>
<td id="T_9106b_row9_col17" class="data row9 col17">0</td>
</tr>
<tr class="odd">
<td id="T_9106b_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">10</td>
<td id="T_9106b_row10_col0" class="data row10 col0">0</td>
<td id="T_9106b_row10_col1" class="data row10 col1">0</td>
<td id="T_9106b_row10_col2" class="data row10 col2">0</td>
<td id="T_9106b_row10_col3" class="data row10 col3">0</td>
<td id="T_9106b_row10_col4" class="data row10 col4">0</td>
<td id="T_9106b_row10_col5" class="data row10 col5">0</td>
<td id="T_9106b_row10_col6" class="data row10 col6">0</td>
<td id="T_9106b_row10_col7" class="data row10 col7">43</td>
<td id="T_9106b_row10_col8" class="data row10 col8">98</td>
<td id="T_9106b_row10_col9" class="data row10 col9">98</td>
<td id="T_9106b_row10_col10" class="data row10 col10">208</td>
<td id="T_9106b_row10_col11" class="data row10 col11">253</td>
<td id="T_9106b_row10_col12" class="data row10 col12">253</td>
<td id="T_9106b_row10_col13" class="data row10 col13">253</td>
<td id="T_9106b_row10_col14" class="data row10 col14">253</td>
<td id="T_9106b_row10_col15" class="data row10 col15">187</td>
<td id="T_9106b_row10_col16" class="data row10 col16">22</td>
<td id="T_9106b_row10_col17" class="data row10 col17">0</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="baseline-model-pixel-similarity" class="level2">
<h2 class="anchored" data-anchor-id="baseline-model-pixel-similarity">Baseline Model: Pixel Similarity</h2>
<p>The problem we’re trying to solve is the following: How do we write a computer program to be able to distinguish between images of handwritten 3 and 7 digits.</p>
<p>The first approach we try is <strong>Pixel Similarity</strong>. The FASTAI book authors define this as the following:</p>
<ol type="1">
<li>Take the average pixel value for every pixel of the 3 images and do the same for the 7 images. These averages will produce a baseline image 3 and image 7.</li>
<li>Go through every image in the 3 and 7 images and compare them to the baseline images to see which digit they are most similar to</li>
</ol>
<div class="cell" data-outputid="1156cf26-8173-43f4-89fc-b67b82f55da9" data-execution_count="8">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of tensors for each image in 3 and 7 directories</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>three_tensors <span class="op">=</span> [tensor(Image.<span class="bu">open</span>(o)) <span class="cf">for</span> o <span class="kw">in</span> threes]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>seven_tensors <span class="op">=</span> [tensor(Image.<span class="bu">open</span>(o)) <span class="cf">for</span> o <span class="kw">in</span> sevens]</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of images in threes: </span><span class="sc">{</span><span class="bu">len</span>(threes)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of images in three tensors: </span><span class="sc">{</span><span class="bu">len</span>(three_tensors)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of images in sevens: </span><span class="sc">{</span><span class="bu">len</span>(sevens)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of images in seven tensors: </span><span class="sc">{</span><span class="bu">len</span>(seven_tensors)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># verify images</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>show_image(three_tensors[<span class="dv">1</span>])</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>show_image(seven_tensors[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of images in threes: 6131
Number of images in three tensors: 6131
Number of images in sevens: 6265
Number of images in seven tensors: 6265</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>&lt;Axes: &gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="fastai-lesson3_files/figure-html/cell-9-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="fastai-lesson3_files/figure-html/cell-9-output-4.png" class="img-fluid"></p>
</div>
</div>
<p>The way I understand tensors is that they are data structures for storing information. The way I understand the stack operation is storing all the images into a pile of images that we then then can average all the pixel values for each pixel index in the image.</p>
<div class="cell" data-outputid="62223bfa-8fcf-4be2-9d5b-aa8e6ffeb049" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the average intensity of each pixel across all images for 3 and 7</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>stacked_sevens <span class="op">=</span> torch.stack(seven_tensors).<span class="bu">float</span>() <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>stacked_threes <span class="op">=</span> torch.stack(three_tensors).<span class="bu">float</span>() <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"stacked_sevens shape: </span><span class="sc">{</span>stacked_sevens<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"stacked_sevens tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(stacked_sevens.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"stacked_threes shape: </span><span class="sc">{</span>stacked_threes<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"stacked_threes tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(stacked_threes.shape)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>stacked_sevens shape: torch.Size([6265, 28, 28])
stacked_sevens tensor rank: 3
stacked_threes shape: torch.Size([6131, 28, 28])
stacked_threes tensor rank: 3</code></pre>
</div>
</div>
<p>In this step, we take the list of tensor images and condense them down into a new image where each pixel index in this new image is the average of all the values at a particular index.</p>
<div class="cell" data-outputid="c38f69b1-dc75-40e6-9618-fb47fc032ffd" data-execution_count="10">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a> <span class="co"># Average of all image tensors by taking mean along the 0 dimension (collapse all the rows into a single row) of stacked 3 rank tensors</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>mean3 <span class="op">=</span> stacked_threes.mean(<span class="dv">0</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>mean7 <span class="op">=</span> stacked_sevens.mean(<span class="dv">0</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"mean3 shape: </span><span class="sc">{</span>mean3<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"mean3 tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(mean3.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"mean7 shape: </span><span class="sc">{</span>mean7<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"mean7 tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(mean7.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>show_image(mean3)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>show_image(mean7)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>mean3 shape: torch.Size([28, 28])
mean3 tensor rank: 2
mean7 shape: torch.Size([28, 28])
mean7 tensor rank: 2</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>&lt;Axes: &gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="fastai-lesson3_files/figure-html/cell-11-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="fastai-lesson3_files/figure-html/cell-11-output-4.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="measuring-distance" class="level2">
<h2 class="anchored" data-anchor-id="measuring-distance">Measuring Distance</h2>
<p>To compare the baseline image with a randomly chosen image from one of the datasets we need to measure the difference between pixels such that we have a standardized form so that the differences accurately reflect what pixels are dark and light when comparing the two images.</p>
<div class="cell" data-outputid="52fd0c5e-f103-4346-d91e-40d21d32553e" data-execution_count="11">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean Absolute Difference (L1 Norm)</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>a_3 <span class="op">=</span> stacked_threes[<span class="dv">1</span>]</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>a_7 <span class="op">=</span> stacked_sevens[<span class="dv">1</span>]</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>dist_3_abs <span class="op">=</span> (a_3 <span class="op">-</span> mean3).<span class="bu">abs</span>().mean()</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>dist_7_abs <span class="op">=</span> (a_7 <span class="op">-</span> mean7).<span class="bu">abs</span>().mean()</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Absolute Difference between 3 image and ideal 3 image: </span><span class="sc">{</span>dist_3_abs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Absolute Difference between 7 image and ideal 7 image: </span><span class="sc">{</span>dist_7_abs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co"># see how close 3 is to ideal 7</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>dist_test_abs <span class="op">=</span> (a_3 <span class="op">-</span> mean7).<span class="bu">abs</span>().mean()</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Absolute Difference between 3 image and ideal 7 image: </span><span class="sc">{</span>dist_test_abs<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Absolute Difference between 3 image and ideal 3 image: 0.11143654584884644
Mean Absolute Difference between 7 image and ideal 7 image: 0.13037648797035217
Mean Absolute Difference between 3 image and ideal 7 image: 0.15861910581588745</code></pre>
</div>
</div>
<div class="cell" data-outputid="91b584b0-7ea6-489c-b48b-1f460fcb90b9" data-execution_count="12">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Root Mean Squared Error (L2 Norm)</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>a_3 <span class="op">=</span> stacked_threes[<span class="dv">1</span>]</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>a_7 <span class="op">=</span> stacked_sevens[<span class="dv">1</span>]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>dist_3_sqr <span class="op">=</span> ((a_3 <span class="op">-</span> mean3)<span class="op">**</span><span class="dv">2</span>).mean().sqrt()</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>dist_7_sqr <span class="op">=</span> ((a_7 <span class="op">-</span> mean7)<span class="op">**</span><span class="dv">2</span>).mean().sqrt()</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>dist_test_sqr <span class="op">=</span> ((a_3 <span class="op">-</span> mean7)<span class="op">**</span><span class="dv">2</span>).mean().sqrt()</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Root Mean Squared Difference between 3 image and ideal 3 image: </span><span class="sc">{</span>dist_3_sqr<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Root Mean Squared Difference between 7 image and ideal 7 image: </span><span class="sc">{</span>dist_7_sqr<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co"># see how close 3 is to ideal 7</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Root Mean Squared Difference between 3 image and ideal 7 image: </span><span class="sc">{</span>dist_test_sqr<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Root Mean Squared Difference between 3 image and ideal 3 image: 0.20208320021629333
Root Mean Squared Difference between 7 image and ideal 7 image: 0.2584923207759857
Root Mean Squared Difference between 3 image and ideal 7 image: 0.30210891366004944</code></pre>
</div>
</div>
<div class="cell" data-outputid="19a15a6c-7739-4a1d-e4ab-fe5bcbbebcbf" data-execution_count="13">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pytorch Mean Squared Error and Mean Absolute Value Loss</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Pytorch Mean Absolute Value Loss between 3 image and ideal 7 image: </span><span class="sc">{</span>F<span class="sc">.</span>l1_loss(a_3.<span class="bu">float</span>(), mean7)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Pytorch Mean Squared Error Loss between 3 image and ideal 7 image: </span><span class="sc">{</span>F<span class="sc">.</span>mse_loss(a_3, mean7)<span class="sc">.</span>sqrt()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Pytorch Mean Absolute Value Loss between 3 image and ideal 7 image: 0.15861910581588745
Pytorch Mean Squared Error Loss between 3 image and ideal 7 image: 0.30210891366004944</code></pre>
</div>
</div>
</section>
<section id="pytorch-numpy" class="level2">
<h2 class="anchored" data-anchor-id="pytorch-numpy">Pytorch + Numpy</h2>
<p>The main difference between pytorch and numpy is that pytorch supports using the GPU and calculating gradients which numpy does not.</p>
<div class="cell" data-outputid="653bbebd-adcb-4289-8d35-f343804b2ccc" data-execution_count="14">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]]</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co"># numpy array</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>arr <span class="op">=</span> array(data)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>tns <span class="op">=</span> tensor(data)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># select a row</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"select the second row of tensor: </span><span class="sc">{</span>tns[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co"># select a column</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"select the second column of tensor: </span><span class="sc">{</span>tns[:<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># slicing</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"select slice of tensor: </span><span class="sc">{</span>tns[<span class="dv">1</span>, <span class="dv">1</span>:<span class="dv">3</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co"># addition</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Addition with tensors: </span><span class="sc">{</span>tns <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="co"># types</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"tensor type: </span><span class="sc">{</span>tns<span class="sc">.</span><span class="bu">type</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="co"># scale and update tensor type</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"changing tensor type from int to float: </span><span class="sc">{</span>tns <span class="op">*</span> <span class="fl">1.5</span><span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>select the second row of tensor: tensor([4, 5, 6])
select the second column of tensor: tensor([[1, 2, 3]])
select slice of tensor: tensor([5, 6])
Addition with tensors: tensor([[2, 3, 4],
        [5, 6, 7]])
tensor type: torch.LongTensor
changing tensor type from int to float: tensor([[1.5000, 3.0000, 4.5000],
        [6.0000, 7.5000, 9.0000]])</code></pre>
</div>
</div>
</section>
<section id="computing-metrics" class="level2">
<h2 class="anchored" data-anchor-id="computing-metrics">Computing Metrics</h2>
<p>A metric is a number that is calculated based on the predictions of the model and the correct labels and inform us how good the model is. For classification models, <strong>accuracy</strong> is a popular metric.</p>
<div class="cell" data-outputid="9a15b9eb-b26f-4ae5-a667-ababb24c8a28" data-execution_count="15">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create validation data set</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>valid_3_tens <span class="op">=</span> torch.stack([tensor(Image.<span class="bu">open</span>(o))</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>                            <span class="cf">for</span> o <span class="kw">in</span> (path<span class="op">/</span><span class="st">'valid'</span><span class="op">/</span><span class="st">'3'</span>).ls()])</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>valid_3_tens <span class="op">=</span> valid_3_tens.<span class="bu">float</span>() <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>valid_7_tens <span class="op">=</span> torch.stack([tensor(Image.<span class="bu">open</span>(o))</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>                            <span class="cf">for</span> o <span class="kw">in</span> (path<span class="op">/</span><span class="st">'valid'</span><span class="op">/</span><span class="st">'7'</span>).ls()])</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>valid_7_tens <span class="op">=</span> valid_7_tens.<span class="bu">float</span>() <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"3 validation set shape: </span><span class="sc">{</span>valid_3_tens<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"3 validation set tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(valid_3_tens.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"7 validation set shape: </span><span class="sc">{</span>valid_7_tens<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"7 validation set tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(valid_7_tens.shape)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3 validation set shape: torch.Size([1010, 28, 28])
3 validation set tensor rank: 3
7 validation set shape: torch.Size([1028, 28, 28])
7 validation set tensor rank: 3</code></pre>
</div>
</div>
<div class="cell" data-outputid="0e1aff34-5d3a-47ee-f234-ae842ef21c00" data-execution_count="16">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MNIST Data Distance Function</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mnist_distance(a, b):</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># (-1, -2) represent a range of axes. Tell Pytorch to take the mean ranging over the values</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># indexed by the last two axes of the tensor (horizontal and vertical dimensions of the image)</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># leaves only the first tensor axis which indexes over images and the final size -&gt; averaged the intensity of all the pixels</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># in the image</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (a <span class="op">-</span> b).<span class="bu">abs</span>().mean((<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">2</span>))</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Distance function measuring the distance between 3 image and ideal 3 image: </span><span class="sc">{</span>mnist_distance(a_3, mean3)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># measure distance between validation set 3 and ideal 3 tensor</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>valid_3_dist <span class="op">=</span> mnist_distance(valid_3_tens, mean3)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Distance between validation set 3 image and ideal training data set 3 image: </span><span class="sc">{</span>valid_3_dist<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Valid 3 distance tensor shape: </span><span class="sc">{</span>valid_3_dist<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Valid 3 distance tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(valid_3_dist.shape)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Distance function measuring the distance between 3 image and ideal 3 image: 0.11143654584884644
Distance between validation set 3 image and ideal training data set 3 image: tensor([0.1163, 0.1464, 0.1188,  ..., 0.1508, 0.1018, 0.1285])
Valid 3 distance tensor shape: torch.Size([1010])
Valid 3 distance tensor rank: 1</code></pre>
</div>
</div>
<div class="cell" data-outputid="b5bb6c3a-40b1-469f-ad56-eb35923adc41" data-execution_count="17">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check if image is a 3</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> is_3(x):</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> mnist_distance(x, mean3) <span class="op">&lt;</span> mnist_distance(x, mean7)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Check if 3 image is actually a 3 image as a boolean: </span><span class="sc">{</span>is_3(a_3)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1.0 - true</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.0 - false</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Check if 3 image is actually a 3 image as a float: </span><span class="sc">{</span>is_3(a_3)<span class="sc">.</span><span class="bu">float</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co"># check all 3 images</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"check if all 3 images in validation set are 3 images: </span><span class="sc">{</span>is_3(valid_3_tens)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Check if 3 image is actually a 3 image as a boolean: True
Check if 3 image is actually a 3 image as a float: 1.0
check if all 3 images in validation set are 3 images: tensor([True, True, True,  ..., True, True, True])</code></pre>
</div>
</div>
<div class="cell" data-outputid="8400652a-47dd-4950-db4d-742c8a1ee57a" data-execution_count="18">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Accuracy of 3 and 7 Images</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>accuracy_3s <span class="op">=</span> is_3(valid_3_tens).<span class="bu">float</span>() .mean()</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>accuracy_7s <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> is_3(valid_7_tens).<span class="bu">float</span>()).mean()</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model accuracy for classifying 3 images: </span><span class="sc">{</span>accuracy_3s<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model accuracy for classifying 7 images: </span><span class="sc">{</span>accuracy_7s<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average model accuracy for classifying 3 and 7 images: </span><span class="sc">{</span>(accuracy_3s<span class="op">+</span>accuracy_7s)<span class="op">/</span><span class="dv">2</span><span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model accuracy for classifying 3 images: 0.9168316721916199
Model accuracy for classifying 7 images: 0.9854085445404053
Average model accuracy for classifying 3 and 7 images: 0.951120138168335</code></pre>
</div>
</div>
</section>
<section id="stochastic-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="stochastic-gradient-descent">Stochastic Gradient Descent</h2>
<p>In the <strong>Pixel Similarity</strong> approach from above, we don’t have a way for the model to learn and improve its accuracy. Instead of trying to compare an image with an ideal image, we can use <strong>Stochastic Gradient Descent (SGD)</strong> to look at each individual pixel and come up with a set of weights with large weights associated with pixels that are the most black for a particular label (ie. digit in MNIST data) using Arthur Samuel’s definition of machine learning</p>
<section id="stochastic-gradient-descent-steps-for-an-image-classifier" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-gradient-descent-steps-for-an-image-classifier">Stochastic Gradient Descent Steps for an Image Classifier</h3>
<ol type="1">
<li>initialize weights</li>
<li>Calculate Predictions</li>
<li>Based on the predictions, calculate how good the model is (its loss)</li>
<li>Calculate the gradient which measures for each weight, how changing that weight would change the loss</li>
<li>Step (change) all the weights based on Step 4</li>
<li>Go back to Step 2 and repeat the process</li>
<li>Iterate until you decide to stop the training process until you decide the model is good enough for your problem</li>
</ol>
<p>The problem below is an example from the FastAI Book simulating a roller coaster and trying to find a function that best fits the data to understand how speed changes over time</p>
<div class="cell" data-outputid="2590d8af-3f36-4b49-dbfc-21c45d18f101" data-execution_count="19">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Roller Coaster Problem with Stochastic Gradient Descent</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># generate data</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>time <span class="op">=</span> torch.arange(<span class="dv">0</span>,<span class="dv">20</span>).<span class="bu">float</span>()</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>speed <span class="op">=</span> torch.randn(<span class="dv">20</span>) <span class="op">*</span> <span class="dv">3</span> <span class="op">+</span> <span class="fl">0.75</span> <span class="op">*</span> (time <span class="op">-</span> <span class="fl">9.5</span>)<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(time,speed)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># use SGD to find a function that fits the data for the rollercoaster data</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co"># t - the time when we are measuring the rollercoaster speed</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co"># params - the values that define which quadratic we're trying</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(t, params):</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    a,b,c <span class="op">=</span> params</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a <span class="op">*</span> (t<span class="op">**</span><span class="dv">2</span>) <span class="op">+</span> (b <span class="op">*</span> t) <span class="op">+</span> c</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a loss function - returns a value based on a prediction and a target</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="co"># where lower values of the functions correspond to better predictions. Need</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="co">#  loss function to return lower values when predictions are more accurate, as</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="co">#  SGD is trying to minimize this loss. For continuous data, Mean Square Error is</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co">#  frequently used</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse(preds, targets):</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> ((preds<span class="op">-</span>targets)<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a><span class="co"># SGD Process</span></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a><span class="co"># function for visualizing how close our predictions are to targets</span></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_preds(preds, ax<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ax <span class="kw">is</span> <span class="va">None</span>: ax<span class="op">=</span>plt.subplots()[<span class="dv">1</span>]</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>    ax.scatter(time, speed)</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>    ax.scatter(time, to_np(preds), color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>    ax.set_ylim(<span class="op">-</span><span class="dv">300</span>,<span class="dv">100</span>)</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. initialize weights</span></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> torch.randn(<span class="dv">3</span>).requires_grad_()</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The parameter values after initialization: </span><span class="sc">{</span>params<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>orig_params <span class="op">=</span> params.clone()</span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The original parameters: </span><span class="sc">{</span>orig_params<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Calculate Predictions</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> f(time, params)</span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>show_preds(preds)</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Based on the predictions, calculate how good the model is (its loss)</span></span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> mse(preds, speed)</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss value: </span><span class="sc">{</span>loss<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Calculate the gradient which measures for each weight, how changing that weight would change the loss</span></span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Gradient values for each argument: </span><span class="sc">{</span>params<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate approximation of how parameters need to change</span></span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test a new gradient with a learning rate of 1e^-5: </span><span class="sc">{</span>params<span class="sc">.</span>grad <span class="op">*</span> <span class="fl">1e-5</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Parameter values after computing the gradient: </span><span class="sc">{</span>params<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Step (change) all the weights based on Step 4</span></span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a>params.data <span class="op">-=</span> learning_rate <span class="op">*</span> params.grad.data</span>
<span id="cb39-54"><a href="#cb39-54" aria-hidden="true" tabindex="-1"></a>params.grad <span class="op">=</span> <span class="va">None</span></span>
<span id="cb39-55"><a href="#cb39-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if loss has improved</span></span>
<span id="cb39-56"><a href="#cb39-56" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> f(time, params)</span>
<span id="cb39-57"><a href="#cb39-57" aria-hidden="true" tabindex="-1"></a>mse(preds, speed)</span>
<span id="cb39-58"><a href="#cb39-58" aria-hidden="true" tabindex="-1"></a>show_preds(preds)</span>
<span id="cb39-59"><a href="#cb39-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-60"><a href="#cb39-60" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Go back to Step 2 and repeat the process</span></span>
<span id="cb39-61"><a href="#cb39-61" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apply_step(params, prn<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb39-62"><a href="#cb39-62" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> f(time, params)</span>
<span id="cb39-63"><a href="#cb39-63" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> mse(preds, speed)</span>
<span id="cb39-64"><a href="#cb39-64" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb39-65"><a href="#cb39-65" aria-hidden="true" tabindex="-1"></a>    params.data <span class="op">-=</span> learning_rate <span class="op">*</span> params.grad.data</span>
<span id="cb39-66"><a href="#cb39-66" aria-hidden="true" tabindex="-1"></a>    params.grad <span class="op">=</span> <span class="va">None</span></span>
<span id="cb39-67"><a href="#cb39-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> prn:</span>
<span id="cb39-68"><a href="#cb39-68" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f"Loss Value: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-69"><a href="#cb39-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> preds</span>
<span id="cb39-70"><a href="#cb39-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-71"><a href="#cb39-71" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb39-72"><a href="#cb39-72" aria-hidden="true" tabindex="-1"></a>  apply_step(params)</span>
<span id="cb39-73"><a href="#cb39-73" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> orig_params.detach().requires_grad_()</span>
<span id="cb39-74"><a href="#cb39-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-75"><a href="#cb39-75" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Iterate until you decide to stop the training process until you decide the model is good enough for your problem</span></span>
<span id="cb39-76"><a href="#cb39-76" aria-hidden="true" tabindex="-1"></a>_,axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">4</span>,figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">3</span>))</span>
<span id="cb39-77"><a href="#cb39-77" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axs: show_preds(apply_step(params, <span class="va">False</span>), ax)</span>
<span id="cb39-78"><a href="#cb39-78" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The parameter values after initialization: tensor([ 0.2816,  0.9605, -1.2062], requires_grad=True)
The original parameters: tensor([ 0.2816,  0.9605, -1.2062], grad_fn=&lt;CloneBackward0&gt;)
Loss value: 1770.0677490234375
Gradient values for each argument: tensor([11310.8789,   742.4634,    34.8602])
Test a new gradient with a learning rate of 1e^-5: tensor([0.1131, 0.0074, 0.0003])
Parameter values after computing the gradient: tensor([ 0.2816,  0.9605, -1.2062], requires_grad=True)
Loss Value: 848.1575927734375
Loss Value: 673.7000732421875
Loss Value: 640.683349609375
Loss Value: 634.4315795898438
Loss Value: 633.2445068359375
Loss Value: 633.0159301757812
Loss Value: 632.9686279296875
Loss Value: 632.9556884765625
Loss Value: 632.94921875
Loss Value: 632.9440307617188</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="fastai-lesson3_files/figure-html/cell-20-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="fastai-lesson3_files/figure-html/cell-20-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="fastai-lesson3_files/figure-html/cell-20-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="fastai-lesson3_files/figure-html/cell-20-output-5.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="building-the-mnist-image-classifier" class="level2">
<h2 class="anchored" data-anchor-id="building-the-mnist-image-classifier">Building the MNIST Image Classifier</h2>
<section id="training-dataset" class="level3">
<h3 class="anchored" data-anchor-id="training-dataset">Training Dataset</h3>
<div class="cell" data-outputid="16886eb9-59cb-480a-d302-5fa530f81a79" data-execution_count="20">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build Training Dataset</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># -1 view function -&gt; make this axis as big as necessary to fit all the data</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>train_x <span class="op">=</span> torch.cat([stacked_threes, stacked_sevens]).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span><span class="op">*</span><span class="dv">28</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>train_y <span class="op">=</span> tensor([<span class="dv">1</span>]<span class="op">*</span><span class="bu">len</span>(threes) <span class="op">+</span> [<span class="dv">0</span>]<span class="op">*</span><span class="bu">len</span>(sevens)).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train_x data shape: </span><span class="sc">{</span>train_x<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train_x data tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(train_x.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train_y data shape: </span><span class="sc">{</span>train_y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train_y data tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(train_y.shape)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>train_x data shape: torch.Size([12396, 784])
train_x data tensor rank: 2
train_y data shape: torch.Size([12396, 1])
train_y data tensor rank: 2</code></pre>
</div>
</div>
</section>
<section id="validation-dataset" class="level3">
<h3 class="anchored" data-anchor-id="validation-dataset">Validation Dataset</h3>
<div class="cell" data-outputid="72211316-50d2-4c75-e735-beaeb05285ea" data-execution_count="21">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build Validation Dataset</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>valid_x <span class="op">=</span> torch.cat([valid_3_tens, valid_7_tens]).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span><span class="op">*</span><span class="dv">28</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>valid_y <span class="op">=</span> tensor([<span class="dv">1</span>]<span class="op">*</span><span class="bu">len</span>(valid_3_tens) <span class="op">+</span> [<span class="dv">0</span>]<span class="op">*</span><span class="bu">len</span>(valid_7_tens)).unsqueeze(<span class="dv">1</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"valid_x data shape: </span><span class="sc">{</span>valid_x<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"valid_x data tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(valid_x.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"valid_y data shape: </span><span class="sc">{</span>valid_y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"valid_y data tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(valid_y.shape)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>valid_x data shape: torch.Size([2038, 784])
valid_x data tensor rank: 2
valid_y data shape: torch.Size([2038, 1])
valid_y data tensor rank: 2</code></pre>
</div>
</div>
<div class="cell" data-outputid="b880852e-786e-4af3-b64e-7535d64846ce" data-execution_count="22">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a Dataset object(training data) for PyTorch</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset is required to return a tuple of (x, y) when indexed</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>dset <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(train_x,train_y))</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>x,y <span class="op">=</span> dset[<span class="dv">0</span>]</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"datset x shape: </span><span class="sc">{</span>x<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"dataset x tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(x.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"datset y shape: </span><span class="sc">{</span>y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"dataset y tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(y.shape)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>datset x shape: torch.Size([784])
dataset x tensor rank: 1
datset y shape: torch.Size([1])
dataset y tensor rank: 1</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a Dataset object(validation data) for PyTorch</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset is required to return a tuple of (x, y) when indexed</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>valid_dset <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(valid_x,valid_y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="initialize-model-weights" class="level3">
<h3 class="anchored" data-anchor-id="initialize-model-weights">Initialize Model Weights</h3>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize model weights</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_params(size, std<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (torch.randn(size)<span class="op">*</span>std).requires_grad_()</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> init_params((<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>,<span class="dv">1</span>))</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a Bias Value</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="co"># need a bias to ensure its not 0 when the pixels are 0</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>bias <span class="op">=</span> init_params(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="88248cc1-5ed1-4ac4-b218-aea35c1113ad" data-execution_count="25">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate a prediction for one image</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Prediction for a single image from training data: </span><span class="sc">{</span>(train_x[<span class="dv">0</span>]<span class="op">*</span>weights.T)<span class="sc">.</span><span class="bu">sum</span>() <span class="op">+</span> bias<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Prediction for a single image from training data: tensor([-4.6132], grad_fn=&lt;AddBackward0&gt;)</code></pre>
</div>
</div>
</section>
<section id="linear-classifier" class="level3">
<h3 class="anchored" data-anchor-id="linear-classifier">Linear Classifier</h3>
<div class="cell" data-outputid="0b5d74ce-8cbd-45ef-d00a-4312f0daf815" data-execution_count="26">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrix Multiplication</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  Create a linear combination for the prediction values</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co"># compute predictions for all the images in the training data</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> linear1(xb):</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> xb<span class="op">@</span>weights <span class="op">+</span> bias</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> linear1(train_x)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predictions"</span>)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(preds)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Prediction shape: </span><span class="sc">{</span>preds<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Prediction tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(preds.shape)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Predictions
tensor([[-4.6132],
        [-8.5214],
        [-6.7243],
        ...,
        [-6.6400],
        [ 3.2664],
        [-6.1007]], grad_fn=&lt;AddBackward0&gt;)
Prediction shape: torch.Size([12396, 1])
Prediction tensor rank: 2</code></pre>
</div>
</div>
<div class="cell" data-outputid="fc87adf4-1273-408f-ec1b-a95430ff67fb" data-execution_count="27">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check accuracy of prediction</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>corrects <span class="op">=</span> (preds<span class="op">&gt;</span><span class="fl">0.0</span>).<span class="bu">float</span>() <span class="op">==</span> train_y</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy of Predictions: </span><span class="sc">{</span>corrects<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average accuracy of all predictions: </span><span class="sc">{</span>corrects<span class="sc">.</span><span class="bu">float</span>()<span class="sc">.</span>mean()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy of Predictions: tensor([[False],
        [False],
        [False],
        ...,
        [ True],
        [False],
        [ True]])
Average accuracy of all predictions: 0.36156824231147766</code></pre>
</div>
</div>
<div class="cell" data-outputid="d902f296-7257-4deb-92bf-e0e34ae9fd34" data-execution_count="28">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Improve Accuracy</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="co"># test to see if we can improve accuracy with a small change</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>  weights[<span class="dv">0</span>] <span class="op">*=</span> <span class="fl">1.0001</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> linear1(train_x)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average accuracy after updating the weights: </span><span class="sc">{</span>((preds<span class="op">&gt;</span><span class="fl">0.0</span>).<span class="bu">float</span>() <span class="op">==</span> train_y)<span class="sc">.</span><span class="bu">float</span>()<span class="sc">.</span>mean()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a><span class="co"># there is no change because the change in weights is so small that (y_new - y_old) is very close to 0 ie.</span></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="co"># the gradient is almost 0 everywhere</span></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a><span class="co"># need to find a loss function which when our weights result in slightly better predictions produces a slightly better loss</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Average accuracy after updating the weights: 0.36156824231147766</code></pre>
</div>
</div>
</section>
<section id="loss-function" class="level3">
<h3 class="anchored" data-anchor-id="loss-function">Loss Function</h3>
<div class="cell" data-outputid="c87dd300-dc32-4dcd-f1ce-a9caea5a65eb" data-execution_count="29">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a Loss Function</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="co"># loss function receive predictions from the model about the images</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="co"># the purpose of the loss function is to measure the difference between predicted values and true values ie the labels</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>trgts  <span class="op">=</span> tensor([<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>prds   <span class="op">=</span> tensor([<span class="fl">0.9</span>, <span class="fl">0.4</span>, <span class="fl">0.2</span>])</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="co"># first attempt at a loss function</span></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mnist_loss(predictions, targets):</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># measures how distant each predictions is from 1 if it should be 1, how distant it is from 0 if it should be 0</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># and takes the mean of all the distances</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.where(targets<span class="op">==</span><span class="dv">1</span>, <span class="dv">1</span><span class="op">-</span>predictions, predictions).mean()</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a><span class="co"># need a scalar for the final loss -&gt; the lower the loss value the better</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a><span class="co"># indicates accurate predictions are more confident and when inaccurate predictions are less confident</span></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test loss function: </span><span class="sc">{</span>mnist_loss(prds,trgts)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a><span class="co"># issue with this loss function is that it assumes all predictions are between 0 and 1</span></span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a><span class="co"># sigmoid function always outputs a number between 0 and 1</span></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(x):</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>torch.exp(<span class="op">-</span>x))</span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a><span class="co"># second attempt at a loss function using sigmoid</span></span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mnist_loss_sigmoid(predictions, targets):</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> predictions.sigmoid()</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.where(targets<span class="op">==</span><span class="dv">1</span>, <span class="dv">1</span><span class="op">-</span>predictions, predictions).mean()</span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test loss function with sigmoid: </span><span class="sc">{</span>mnist_loss_sigmoid(prds,trgts)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Test loss function: 0.43333330750465393
Test loss function with sigmoid: 0.44596806168556213</code></pre>
</div>
</div>
</section>
<section id="sgd-mini-batches" class="level3">
<h3 class="anchored" data-anchor-id="sgd-mini-batches">SGD + Mini Batches</h3>
<div class="cell" data-outputid="494b372f-6865-4898-a28e-9e1d995d3e6d" data-execution_count="30">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SGD + Mini Batches</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimization Step - updating the weights based on gradients</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co"># need to calculate loss over one or more data items</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Solution: Calculate the average loss for a data items at a time (mini-batch)</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Batch Size - number of items in mini batch</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="co"># use fastai to build a dataloader object to shuffle data</span></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="co"># randomly shuffle data on every epoch before creating mini batches</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>coll <span class="op">=</span> <span class="bu">range</span>(<span class="dv">15</span>)</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>dl <span class="op">=</span> DataLoader(coll, batch_size<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Example of randomly generated mini-batch of batch size 5: </span><span class="sc">{</span><span class="bu">list</span>(dl)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Example of randomly generated mini-batch of batch size 5: [tensor([12,  0,  7,  6,  9]), tensor([ 2, 13,  3, 14, 11]), tensor([ 4,  5,  1,  8, 10])]</code></pre>
</div>
</div>
</section>
<section id="mnist-model-training-loop-using-sgd" class="level3">
<h3 class="anchored" data-anchor-id="mnist-model-training-loop-using-sgd">MNIST Model Training Loop using SGD</h3>
<div class="cell" data-outputid="15cf0e9d-018e-4ba1-8b38-5edf7c8e0864" data-execution_count="31">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a training loop for a model</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize weights and bias randomly</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> init_params((<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>,<span class="dv">1</span>))</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>bias <span class="op">=</span> init_params(<span class="dv">1</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataLoader for the training data</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>dl <span class="op">=</span> DataLoader(dset, batch_size<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>xb,yb <span class="op">=</span> first(dl)</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"xb shape: </span><span class="sc">{</span>xb<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"xb tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(xb.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"yb shape: </span><span class="sc">{</span>yb<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"yb tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(yb.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataLoader for the validation data</span></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="op">=</span> DataLoader(valid_dset, batch_size<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Mini-Batch of batch size 4 for testing</span></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>batch <span class="op">=</span> train_x[:<span class="dv">4</span>]</span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"batch shape: </span><span class="sc">{</span>batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"batch tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(batch.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Predictions</span></span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a><span class="co"># preds = linear1(batch)</span></span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"predictions: {preds}")</span></span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Measure loss</span></span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a><span class="co"># loss = mnist_loss_sigmoid(preds, train_y[:4])</span></span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Loss: {loss}")</span></span>
<span id="cb61-29"><a href="#cb61-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-30"><a href="#cb61-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Gradients</span></span>
<span id="cb61-31"><a href="#cb61-31" aria-hidden="true" tabindex="-1"></a><span class="co"># loss.backward()</span></span>
<span id="cb61-32"><a href="#cb61-32" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"weights gradient shape: {weights.grad.shape}")</span></span>
<span id="cb61-33"><a href="#cb61-33" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Average of weight gradients: {weights.grad.mean()}")</span></span>
<span id="cb61-34"><a href="#cb61-34" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"bias gradient: {bias.grad}")</span></span>
<span id="cb61-35"><a href="#cb61-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-36"><a href="#cb61-36" aria-hidden="true" tabindex="-1"></a><span class="co"># function for calculating gradient</span></span>
<span id="cb61-37"><a href="#cb61-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_grad(xb, yb, model):</span>
<span id="cb61-38"><a href="#cb61-38" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> model(xb)</span>
<span id="cb61-39"><a href="#cb61-39" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> mnist_loss(preds, yb)</span>
<span id="cb61-40"><a href="#cb61-40" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb61-41"><a href="#cb61-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-42"><a href="#cb61-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test calculating gradients: </span><span class="sc">{</span>calc_grad(batch, train_y[:<span class="dv">4</span>], linear1)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-43"><a href="#cb61-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average of weight gradients: </span><span class="sc">{</span>weights<span class="sc">.</span>grad<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-44"><a href="#cb61-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"bias gradient: </span><span class="sc">{</span>bias<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-45"><a href="#cb61-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-46"><a href="#cb61-46" aria-hidden="true" tabindex="-1"></a><span class="co"># loss.backward adds the gradients of loss to any gradients that are currently stored</span></span>
<span id="cb61-47"><a href="#cb61-47" aria-hidden="true" tabindex="-1"></a><span class="co"># so have to set the current gradients to 0 first</span></span>
<span id="cb61-48"><a href="#cb61-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-49"><a href="#cb61-49" aria-hidden="true" tabindex="-1"></a><span class="co"># training loop for an epoch</span></span>
<span id="cb61-50"><a href="#cb61-50" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_epoch(model, lr, params):</span>
<span id="cb61-51"><a href="#cb61-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> xb,yb <span class="kw">in</span> dl:</span>
<span id="cb61-52"><a href="#cb61-52" aria-hidden="true" tabindex="-1"></a>        calc_grad(xb, yb, model)</span>
<span id="cb61-53"><a href="#cb61-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> params:</span>
<span id="cb61-54"><a href="#cb61-54" aria-hidden="true" tabindex="-1"></a>            p.data <span class="op">-=</span> p.grad<span class="op">*</span>lr</span>
<span id="cb61-55"><a href="#cb61-55" aria-hidden="true" tabindex="-1"></a>            p.grad.zero_()</span>
<span id="cb61-56"><a href="#cb61-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-57"><a href="#cb61-57" aria-hidden="true" tabindex="-1"></a><span class="co"># check accuracy at this point</span></span>
<span id="cb61-58"><a href="#cb61-58" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Check Accuracy at this point: {(preds&gt;0.0).float() == train_y[:4]}")</span></span>
<span id="cb61-59"><a href="#cb61-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-60"><a href="#cb61-60" aria-hidden="true" tabindex="-1"></a><span class="co"># function for calculating validation accuracy</span></span>
<span id="cb61-61"><a href="#cb61-61" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> batch_accuracy(xb, yb):</span>
<span id="cb61-62"><a href="#cb61-62" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> xb.sigmoid()</span>
<span id="cb61-63"><a href="#cb61-63" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> (preds<span class="op">&gt;</span><span class="fl">0.5</span>) <span class="op">==</span> yb</span>
<span id="cb61-64"><a href="#cb61-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> correct.<span class="bu">float</span>().mean()</span>
<span id="cb61-65"><a href="#cb61-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-66"><a href="#cb61-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing batch accuracy: </span><span class="sc">{</span>batch_accuracy(linear1(batch), train_y[:<span class="dv">4</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-67"><a href="#cb61-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-68"><a href="#cb61-68" aria-hidden="true" tabindex="-1"></a><span class="co"># put batches together to create a validation epoch</span></span>
<span id="cb61-69"><a href="#cb61-69" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> validate_epoch(model):</span>
<span id="cb61-70"><a href="#cb61-70" aria-hidden="true" tabindex="-1"></a>    accs <span class="op">=</span> [batch_accuracy(model(xb), yb) <span class="cf">for</span> xb,yb <span class="kw">in</span> valid_dl]</span>
<span id="cb61-71"><a href="#cb61-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">round</span>(torch.stack(accs).mean().item(), <span class="dv">4</span>)</span>
<span id="cb61-72"><a href="#cb61-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-73"><a href="#cb61-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test validation epoch: </span><span class="sc">{</span>validate_epoch(linear1)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-74"><a href="#cb61-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-75"><a href="#cb61-75" aria-hidden="true" tabindex="-1"></a><span class="co"># train for 1 epoch and see if things improve</span></span>
<span id="cb61-76"><a href="#cb61-76" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">1.</span></span>
<span id="cb61-77"><a href="#cb61-77" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> weights, bias</span>
<span id="cb61-78"><a href="#cb61-78" aria-hidden="true" tabindex="-1"></a>train_epoch(linear1, lr, params)</span>
<span id="cb61-79"><a href="#cb61-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"check if accuracy has improved from earlier: </span><span class="sc">{</span>validate_epoch(linear1)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb61-80"><a href="#cb61-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-81"><a href="#cb61-81" aria-hidden="true" tabindex="-1"></a><span class="co"># train for a few epochs</span></span>
<span id="cb61-82"><a href="#cb61-82" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb61-83"><a href="#cb61-83" aria-hidden="true" tabindex="-1"></a>    train_epoch(linear1, lr, params)</span>
<span id="cb61-84"><a href="#cb61-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(validate_epoch(linear1), end<span class="op">=</span><span class="st">' '</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>xb shape: torch.Size([256, 784])
xb tensor rank: 2
yb shape: torch.Size([256, 1])
yb tensor rank: 2
batch shape: torch.Size([4, 784])
batch tensor rank: 2
Test calculating gradients: None
Average of weight gradients: -0.15112045407295227
bias gradient: tensor([-1.])
Testing batch accuracy: 0.25
Test validation epoch: 0.5065
check if accuracy has improved from earlier: 0.946
0.9534 0.9539 0.9534 0.9534 0.9529 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9539 0.9534 0.9534 0.9534 0.9534 </code></pre>
</div>
</div>
</section>
</section>
<section id="pytorch-setup-for-sgd-pytorch-optimizer" class="level2">
<h2 class="anchored" data-anchor-id="pytorch-setup-for-sgd-pytorch-optimizer">PyTorch setup for SGD + Pytorch Optimizer</h2>
<div class="cell" data-outputid="f08774d3-0414-4c07-e675-83e6e6513c31" data-execution_count="32">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build SGD Functionality - PyTorch Optimizer</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="co"># intialize weights and biases in a single pytorch class</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>linear_model <span class="op">=</span> nn.Linear(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>,<span class="dv">1</span>)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>w,b <span class="op">=</span> linear_model.parameters()</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"weights shape: </span><span class="sc">{</span>w<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"weight tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(w.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"bias shape: </span><span class="sc">{</span>b<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"bias tensor rank: </span><span class="sc">{</span><span class="bu">len</span>(b.shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Pytorch Optimizer Setup</span></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BasicOptim:</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,params,lr): <span class="va">self</span>.params,<span class="va">self</span>.lr <span class="op">=</span> <span class="bu">list</span>(params),lr</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.params: p.data <span class="op">-=</span> p.grad.data <span class="op">*</span> <span class="va">self</span>.lr</span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> zero_grad(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.params: p.grad <span class="op">=</span> <span class="va">None</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>weights shape: torch.Size([1, 784])
weight tensor rank: 2
bias shape: torch.Size([1])
bias tensor rank: 1</code></pre>
</div>
</div>
<div class="cell" data-outputid="06966400-c2fc-4de4-a460-f6db33871213" data-execution_count="33">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define training epoch function that use SGD</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> BasicOptim(linear_model.parameters(), lr)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_epoch(model):</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> xb,yb <span class="kw">in</span> dl:</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>        calc_grad(xb, yb, model)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>        opt.step()</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>        opt.zero_grad()</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a><span class="co"># check validation epoch</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Check accuracy after adding SGD: </span><span class="sc">{</span>validate_epoch(linear_model)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Update Model Training</span></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(model, epochs):</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>        train_epoch(model)</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(validate_epoch(model), end<span class="op">=</span><span class="st">' '</span>)</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test training model: </span><span class="sc">{</span>train_model(linear_model, <span class="dv">20</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Check accuracy after adding SGD: 0.5413
0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 0.9534 Test training model: None</code></pre>
</div>
</div>
</section>
<section id="train-mnist-model-using-fastai-library" class="level2">
<h2 class="anchored" data-anchor-id="train-mnist-model-using-fastai-library">Train MNIST Model using FastAI Library</h2>
<div class="cell" data-outputid="36245e95-aa93-4563-c133-29fe20271845" data-execution_count="34">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Modify Model Training Code with FastAI</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="co"># define model information that uses SGD</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="co"># linear_model = nn.Linear(28 * 28,1)</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="co"># opt = SGD(linear_model.parameters(), lr)</span></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a><span class="co"># train_model(linear_model, 20)</span></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define new DataLoaders</span></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> DataLoaders(dl, valid_dl)</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a general purpose Learner class</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, nn.Linear(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>,<span class="dv">1</span>), opt_func<span class="op">=</span>SGD,</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>                loss_func<span class="op">=</span>mnist_loss_sigmoid, metrics<span class="op">=</span>batch_accuracy)</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Train Model with Learner.fit</span></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>learn.fit(<span class="dv">10</span>, lr<span class="op">=</span>lr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">batch_accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.636952</td>
<td>0.503232</td>
<td>0.495584</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.440637</td>
<td>0.235429</td>
<td>0.791462</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.164770</td>
<td>0.166296</td>
<td>0.850834</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.073948</td>
<td>0.102109</td>
<td>0.915604</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.040399</td>
<td>0.075625</td>
<td>0.933268</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>5</td>
<td>0.027231</td>
<td>0.061010</td>
<td>0.948479</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>6</td>
<td>0.021780</td>
<td>0.051817</td>
<td>0.955839</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>7</td>
<td>0.019325</td>
<td>0.045666</td>
<td>0.962709</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.018058</td>
<td>0.041325</td>
<td>0.965162</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>9</td>
<td>0.017283</td>
<td>0.038114</td>
<td>0.967615</td>
<td>00:00</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks">Neural Networks</h2>
<p>Linear classifiers are limited in what they can do. To handle more complex functions we need to add a nonlinear function between two linear classifiers. This is what defines a <strong>neural network</strong>.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define a simple neural network</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="co"># randomly intialize weights and biases</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>w1 <span class="op">=</span> init_params((<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>,<span class="dv">30</span>))</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> init_params(<span class="dv">30</span>)</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>w2 <span class="op">=</span> init_params((<span class="dv">30</span>,<span class="dv">1</span>))</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> init_params(<span class="dv">1</span>)</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a><span class="co"># def simple_net(xb):</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a><span class="co">#     res = xb@w1 + b1</span></span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a><span class="co">#     # Rectified Linear Unit - RELU -&gt; replaces every negative number with 0</span></span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a><span class="co">#     res = res.max(tensor(0.0))</span></span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a><span class="co">#     res = res@w2 + b2</span></span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a><span class="co">#     return res</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pytorch version of a simple neural network</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>simple_net <span class="op">=</span> nn.Sequential(</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>,<span class="dv">30</span>),</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">30</span>,<span class="dv">1</span>)</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="ccdb4868-7db1-4e1f-e3a9-644e8a801d48" data-execution_count="37">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Simplenet to MNIST data</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, simple_net, opt_func<span class="op">=</span>SGD,</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>                loss_func<span class="op">=</span>mnist_loss_sigmoid, metrics<span class="op">=</span>batch_accuracy)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>learn.fit(<span class="dv">40</span>, <span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">batch_accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.282393</td>
<td>0.406792</td>
<td>0.505888</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.134344</td>
<td>0.215805</td>
<td>0.817959</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.076003</td>
<td>0.111737</td>
<td>0.918057</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.051048</td>
<td>0.076866</td>
<td>0.940628</td>
<td>00:01</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.039343</td>
<td>0.060505</td>
<td>0.956330</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>5</td>
<td>0.033269</td>
<td>0.051137</td>
<td>0.962709</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>6</td>
<td>0.029718</td>
<td>0.045164</td>
<td>0.965653</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>7</td>
<td>0.027371</td>
<td>0.041064</td>
<td>0.966634</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.025655</td>
<td>0.038072</td>
<td>0.969087</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>9</td>
<td>0.024313</td>
<td>0.035779</td>
<td>0.970069</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>10</td>
<td>0.023219</td>
<td>0.033955</td>
<td>0.972522</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>11</td>
<td>0.022301</td>
<td>0.032461</td>
<td>0.973503</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>12</td>
<td>0.021518</td>
<td>0.031202</td>
<td>0.976448</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>13</td>
<td>0.020838</td>
<td>0.030122</td>
<td>0.976448</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>14</td>
<td>0.020241</td>
<td>0.029180</td>
<td>0.976938</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>15</td>
<td>0.019713</td>
<td>0.028348</td>
<td>0.977429</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>16</td>
<td>0.019239</td>
<td>0.027608</td>
<td>0.977429</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>17</td>
<td>0.018811</td>
<td>0.026943</td>
<td>0.978410</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>18</td>
<td>0.018422</td>
<td>0.026343</td>
<td>0.978410</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>19</td>
<td>0.018066</td>
<td>0.025798</td>
<td>0.978901</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>20</td>
<td>0.017739</td>
<td>0.025301</td>
<td>0.978901</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>21</td>
<td>0.017437</td>
<td>0.024845</td>
<td>0.979392</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>22</td>
<td>0.017155</td>
<td>0.024425</td>
<td>0.979392</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>23</td>
<td>0.016893</td>
<td>0.024038</td>
<td>0.979882</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>24</td>
<td>0.016647</td>
<td>0.023680</td>
<td>0.980373</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>25</td>
<td>0.016416</td>
<td>0.023348</td>
<td>0.980373</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>26</td>
<td>0.016198</td>
<td>0.023040</td>
<td>0.980373</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>27</td>
<td>0.015992</td>
<td>0.022753</td>
<td>0.980864</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>28</td>
<td>0.015797</td>
<td>0.022486</td>
<td>0.981845</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>29</td>
<td>0.015612</td>
<td>0.022237</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>30</td>
<td>0.015436</td>
<td>0.022004</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>31</td>
<td>0.015268</td>
<td>0.021786</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>32</td>
<td>0.015107</td>
<td>0.021581</td>
<td>0.983317</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>33</td>
<td>0.014954</td>
<td>0.021390</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>34</td>
<td>0.014807</td>
<td>0.021209</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>35</td>
<td>0.014666</td>
<td>0.021039</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>36</td>
<td>0.014531</td>
<td>0.020879</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>37</td>
<td>0.014401</td>
<td>0.020728</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
<tr class="odd">
<td>38</td>
<td>0.014276</td>
<td>0.020584</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
<tr class="even">
<td>39</td>
<td>0.014155</td>
<td>0.020448</td>
<td>0.982826</td>
<td>00:00</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell" data-outputid="d466d41a-189a-4b8d-e00a-300732272778" data-execution_count="38">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the accuracy of model using simplenet</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="co"># y axis - accuracy</span></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="co"># x-axis number of epochs</span></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>plt.plot(L(learn.recorder.values).itemgot(<span class="dv">2</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="fastai-lesson3_files/figure-html/cell-39-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="fd9f4109-2049-4b32-8885-44f7318974aa" data-execution_count="39">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Final Accuracy of model on the MNIST dataset: </span><span class="sc">{</span>learn<span class="sc">.</span>recorder<span class="sc">.</span>values[<span class="op">-</span><span class="dv">1</span>][<span class="dv">2</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Final Accuracy of model on the MNIST dataset: 0.982826292514801</code></pre>
</div>
</div>
</section>
<section id="going-deeper-into-deep-learning-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="going-deeper-into-deep-learning-neural-networks">Going Deeper into Deep Learning + Neural Networks</h2>
<p>The following code below is an 18 layer resnet model with nearly 100% accuracy on the MNIST data. The above code was a simple neural network with 2 layers so the results of resnet-18 on this data show that accuracy improves as we add more layers. One thing to consider are the trade off’s mentioned by Jeremy in the lecture video</p>
<div class="cell" data-outputid="e461ee6e-5eee-4ba5-f9fe-f8243e0b4036" data-execution_count="40">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Going Deeper into Deep Learning + Neural Networks</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> ImageDataLoaders.from_folder(path)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet18, pretrained<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>                    loss_func<span class="op">=</span>F.cross_entropy, metrics<span class="op">=</span>accuracy)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">1</span>, <span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.089190</td>
<td>0.011672</td>
<td>0.998037</td>
<td>00:18</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="terminology" class="level2">
<h2 class="anchored" data-anchor-id="terminology">Terminology</h2>
<p><strong>Activations(Neural Network)</strong> - Numbers that are calculated (both by linear and non-linear layers)</p>
<p><strong>Parameters(Neural Network)</strong> - Numbers that are randomly initialized, and optimized (that is, the numbers that define the model)</p>
<p><strong>Axis(Numpy), Dimensions(PyTorch Tensors)</strong> - For a matrix, the rows and columns define the axis</p>
<p><strong>Tensor Rank</strong> - The number of dimensions in a tensor</p>
<p><strong>Rank Zero Tensor</strong> - Scalar</p>
<p><strong>Rank One Tensor</strong> - Vector</p>
<p><strong>Rank Two Tensor</strong> - Matrix</p>
<p><strong>Nonlinearity (Activation Function)</strong> - one type of layer in a neural network. Typically a neural network alternates between a linear layer and non-linear layer. Occasionally people refer to a single layer = linear layer + nonlinearity</p>
<p><strong>Relu</strong> - Function that returns 0 for negative numbers and doesn’t change positive numbers</p>
<p><strong>Mini-Batch</strong> - A small group of inputs and labels gathered together in two arrays. A gradient desccent step is updated on this batch rather than a whole epoch</p>
<p><strong>Forward Pass</strong> - Applying the model to some input and computing the predictions</p>
<p><strong>Loss</strong> - A value that represents how well (or bad) the model is doing <strong>Gradient</strong> - The derivative(slope) of the loss with respect to some parameter of the model</p>
<p><strong>Backward Pass</strong> - Computing the gradients of the loss with respect to all model parameters</p>
<p><strong>Gradient Descent</strong> - Taking a step in the directions opposite to the gradients to make the model parameters a little bit better</p>
<p><strong>Learning Rate</strong> - The size of the step we take when applying SGD to update the parameters of the model. Usually a very tiny model</p>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=hBBOjCiFcuo">FastAI Lesson 3</a></li>
<li><a href="https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=0rEdjkeOSJbJ">FastAI Chapter 4, MNIST Basics</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work">How Does a Neural Net Really Work</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/which-image-models-are-best/">Which Image Models are Best</a></li>
<li><a href="https://youtu.be/aircAruvnKk?feature=shared">3Blue1Brown Neural Networks</a></li>
<li><a href="https://karpathy.ai/zero-to-hero.html">Andrej Karpathy Neural Networks Zero to Hero</a></li>
<li><a href="https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be">Understanding Dimensions in PyTorch</a></li>
<li><a href="https://medium.com/intuitionmath/numpy-sum-axis-intuition-6eb94926a5d1">Understanding Numpy Axis</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Pytorch Documentation</a></li>
<li><a href="https://docs.fast.ai/">fastai Documentation</a></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>